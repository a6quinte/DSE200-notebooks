{
 "metadata": {
  "name": "",
  "signature": "sha256:1ebc5e8a2b29ea09799575618ce2e0b510245dd5be357e9b030981574663e8be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Generative Models 1: \n",
      "###Naive Bayes Classification of Text\n",
      "\n",
      " - Data Source: http://qwone.com/~jason/20Newsgroups/\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "from math import log10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Define directory and file names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# working directory\n",
      "data_dir = '/Users/a1quintero/Documents/DSE/DSE210-Stats/HW2/20news-clean/'\n",
      "voc_fileName = data_dir + 'vocabulary.txt'\n",
      "\n",
      "# train data filenames\n",
      "dat_trainName = data_dir + 'train.data'\n",
      "lab_trainName = data_dir + 'train.label'\n",
      "map_trainName = data_dir + 'train.map'\n",
      "\n",
      "# test data filenames\n",
      "dat_testName = data_dir + 'test.data'\n",
      "lab_testName = data_dir + 'test.label'\n",
      "map_testName = data_dir + 'test.map'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Read Vocabulary and Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(voc_fileName,'r') as ff:          ## vocabulary set\n",
      "    voc_arr = ff.read().splitlines()\n",
      "with open(map_trainName,'r') as ff:              ## map [className, classID]\n",
      "    map_arr = ff.read().splitlines()\n",
      "\n",
      "### TRAIN DATA \n",
      "with open(lab_trainName,'r') as ff:            ## label: [classLabel] (row number is doc_IDx)\n",
      "    lab_arr = ff.read().splitlines()\n",
      "with open(dat_trainName,'r') as ff:            ## data [ docID, wordID, count ]\n",
      "    dat_arr = ff.read().splitlines()\n",
      "    \n",
      "    \n",
      "### TEST DATA\n",
      "with open(lab_testName,'r') as ff:         ## label: [classLabel] (row number is doc_IDx)\n",
      "    lab_test_arr = ff.read().splitlines()\n",
      "with open(dat_testName,'r') as ff:         ## data [ docID, wordID, count ]\n",
      "    dat_test_arr = ff.read().splitlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data File descriptions:\n",
      "**{train,test}.data files:** ---   \"doc_IDx | word_IDx | count\"\n",
      "\n",
      "**{train,test}.map files:** --- \"list of Classes. line number corresponds to doc_IDx\"\n",
      "\n",
      "**{train,test}.label files:** --- \"ClassName | ClassID\"\n",
      " "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Generate Laplace Smoothed dictionaries of the vocabulary set\n",
      "\n",
      "Here we define a Naive Bayes Classifier Class.  Upon initialization, it uses the given training data to train the model.  It does this by creating an array of dictionaries--one dictionary for each class.  To implement **Laplace Smoothing**, all counts are start at 1 instead of 0. It then adds the frequency of each word (for each class), then normalizes these dictionaries to unity (the sum of all the values is one).  It also finds the fraction of each class that contributes to the training data set (the pi value in the NB equation).\n",
      "\n",
      "The 'predict' method of this class takes the test data and predicts each class.  The atribute created from this is a list of indicies of each predicted class.\n",
      "\n",
      "The 'evaluate' method compares the predicted classes to the actual classes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# naive bayes classifier object\n",
      "\n",
      "class NB_Classifier:\n",
      "    \"\"\"Upon initialization, it uses the given training data to train the model.\n",
      "    It does this by creating an array of dictionaries--one dictionary for each class.\n",
      "    To implement **Laplace Smoothing**, all counts are start at 1 instead of 0. It \n",
      "    then adds the frequency of each word (for each class), then normalizes these \n",
      "    dictionaries to unity (the sum of all the values is one).  It also finds the \n",
      "    fraction of each class that contributes to the training data set (the pi value \n",
      "    in the NB equation).\n",
      "       The 'predict' method of this class takes the test data and predicts each class.\n",
      "    The atribute created from this is a list of indicies of each predicted class.\n",
      "       The 'evaluate' method compares the predicted classes to the actual classes.\n",
      "    \"\"\"\n",
      "    def __init__(self, voc_arr, map_arr, lab_arr, dat_arr):\n",
      "        \"\"\" \n",
      "        Create array of wordBag dictionaries (one per class), then \n",
      "        \n",
      "        \"\"\"\n",
      "        self.vocab_len = len(voc_arr)                # length of vocabulary set\n",
      "        self.n_groups  = len(map_arr)                # number of groups/classes\n",
      "        self.n_docs    = len(lab_arr)                # number of unique documents\n",
      "\n",
      "        self.wordBag_arr = []             # array of dictionaries {wordID:count}\n",
      "        self.pi_arr = []                  # array of pi values (% of docs in each class)\n",
      "        for ii in range( self.n_groups ):\n",
      "            self.pi_arr.append( float(lab_arr.count(str(ii+1)))/float(self.n_docs) )\n",
      "            self.wordBag_arr.append( dict((jj,float(1)) for jj in range(self.vocab_len)) )\n",
      "        \n",
      "        self._fillFrequencyBag_(dat_arr, lab_arr)    # fill dicts with word counts\n",
      "        self._normFrequencyBag_()                    # normalize each to unity\n",
      "        \n",
      "    def predict(self, dat_test_arr):\n",
      "        \"\"\"Running the classification on the test set: Get a dictionary for \n",
      "        each document (only holding onto nonzero values), then get the\n",
      "        best class.\n",
      "        \"\"\"\n",
      "        last_doc = int(dat_test_arr[0].split()[0])  # docID of first line\n",
      "        this_doc_dict = {}\n",
      "        self.mapped_class_arr = []       # output. 1 column list of mapped class index\n",
      "        # run through data, filling mapped_class_arr with best found\n",
      "        for dat_row in dat_test_arr:\n",
      "            # read data\n",
      "            row_arr = dat_row.split()\n",
      "            doc_id  = int( row_arr[0] )\n",
      "            classIndx = int(lab_arr[doc_id-1]) - 1  # class index of this line\n",
      "            word_id = int( row_arr[1] )\n",
      "            wordIndx  = word_id - 1                 # get wordID (key) of this line\n",
      "            word_count = float(row_arr[2])          # frequency in this article\n",
      "            if last_doc == doc_id:\n",
      "                this_doc_dict[wordIndx] = word_count  # add this word to this document\n",
      "            else:      # new document\n",
      "                # predict this document's class\n",
      "                self.mapped_class_arr.append( self._returnBestClassIndx_( this_doc_dict) )\n",
      "                # reset dict for new doc, add first item\n",
      "                this_doc_dict = {}\n",
      "                this_doc_dict[wordIndx] = word_count  # add first word to this document\n",
      "            last_doc = doc_id\n",
      "        # map the final document\n",
      "        self.mapped_class_arr.append( self._returnBestClassIndx_( this_doc_dict) )\n",
      "\n",
      "    def evaluate(self, lab_test_arr):\n",
      "        \"\"\" Evaluates the success of the predicted test data.\n",
      "        \"\"\"\n",
      "        self.conf_mat = []\n",
      "        for ii in range(self.n_groups):\n",
      "            conf_row = []\n",
      "            for jj in range(self.n_groups):\n",
      "                conf_row.append(0)\n",
      "            self.conf_mat.append(conf_row)\n",
      "        ncorrect = 0.0\n",
      "        for class_actual, class_mapped in zip(lab_test_arr, self.mapped_class_arr):\n",
      "            actual_val = int(class_actual)\n",
      "            mapped_val = int(class_mapped + 1)\n",
      "            self.conf_mat[mapped_val-1][actual_val-1] += 1\n",
      "            if actual_val == mapped_val:        \n",
      "                ncorrect += 1        \n",
      "        self.percent_correct = float(ncorrect)/float(len(self.mapped_class_arr))\n",
      "\n",
      "    def confusion_matrix(self):\n",
      "        \"\"\" Plot the confusion matrix.\"\"\"\n",
      "        plt.matshow(self.conf_mat)\n",
      "        plt.colorbar(label='frequency')\n",
      "        plt.ylabel('Predicted Class')\n",
      "        plt.xlabel('Actual Class')\n",
      "    \n",
      "    def _fillFrequencyBag_(self, dat_arr, lab_arr):\n",
      "        \"\"\" For a given array of data (train,test), fill the wordBag_array with the \n",
      "        correct count of the word in each article.\n",
      "        \"\"\"\n",
      "        for dat_row in dat_arr:\n",
      "            row_arr = dat_row.split()\n",
      "            doc_id  = int( row_arr[0] )\n",
      "            classIndx = int(lab_arr[doc_id-1]) - 1    # class index of this line\n",
      "            word_id = int( row_arr[1] )\n",
      "            wordIndx  = word_id - 1                   # get wordID (key) of this line\n",
      "            word_count = int(row_arr[2])              # frequency in this article\n",
      "            self.wordBag_arr[classIndx][wordIndx] += word_count # burstiness correction to go here\n",
      "\n",
      "    def _normFrequencyBag_(self):\n",
      "        \"\"\" Normalizes the frequency dictionary array.\n",
      "        \"\"\"\n",
      "        for tmpIndx,this_dict in enumerate(self.wordBag_arr):\n",
      "            normDict = this_dict.copy()\n",
      "            tot_sum = float( sum(normDict.values()) )\n",
      "            normDict.update((x,y/tot_sum) for x, y in normDict.items())\n",
      "            self.wordBag_arr[tmpIndx] = normDict\n",
      "            \n",
      "    def _returnBestClassIndx_(self, x_counts):\n",
      "        \"\"\"Takes a filled freq dictionary of word counts and returns \n",
      "        the index of the best class via Naive Bayes Classification.\n",
      "        \"\"\"\n",
      "        max_prob = -1e10\n",
      "        best_class = -1\n",
      "        for ii in range( self.n_groups ):  # ii: 0:19\n",
      "            # getting the result of the summation\n",
      "            current_sum = 0.0\n",
      "            for wID,xx in x_counts.items():             # loop over words in dictionary\n",
      "                pp = self.wordBag_arr[ii][wID]          # the 'p' in the equation\n",
      "                current_sum += xx*log10(pp)             # result of the summation\n",
      "            this_prob = log10(self.pi_arr[ii]) + current_sum\n",
      "            if this_prob > max_prob:\n",
      "                max_prob = this_prob\n",
      "                best_class = ii\n",
      "        return best_class"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is how the model is trained:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = NB_Classifier(voc_arr, map_arr, lab_arr, dat_arr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After training, we can then give it the test data for it to predict:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.predict( dat_test_arr )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After it has run on the test data, we can run the evaluate method which calculates the percent correct and generates a confusion matrix.  We also plot the matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.evaluate(lab_test_arr)\n",
      "print \"Percent Correct:\",model.percent_correct\n",
      "model.confusion_matrix()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Percent Correct: 0.78107928048\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAARkAAADyCAYAAAB55LHiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8HFWZ//HPl4Qgm0CMKKuJCi4MBARZxOUiyI9FUEdF\nmFFhVEQZFh3GIShKoowKCOM2LghRXEBQFkHZInIZUFkCJEQSBNQrIJCASACRJcnz++OcTvpeurtO\n163qru5+3q9XvW533VPVpzvp51ad7ZGZ4ZxzZVmt2xVwzvU3DzLOuVJ5kHHOlcqDjHOuVB5knHOl\n8iDjnCvVxG5XwDkXSGprPImZqay6FMmDjHMVcmJiueNLrUWxPMg4VyGrd7sCJfAg41yF9OMXsh/f\nk3M9a81uV6AEHmScqxC/XXLOlaofv5D9+J6c61n9eCXjg/Gcq5CJidtYkp4n6QZJ8yQtlPSFut8d\nKWmRpN9JOqlu/3GS7pJ0h6Q9y3xPlSZpL+DLwATgDDM7KeOQrpM0AjwGLAeeNbMdu1uj0STNBvYF\nlpjZ1nHfZOBc4CXACHCAmT3atUqO0aTOM4EPAQ/FYseZ2eXdqWEx8l7JmNlTknYzsyclTQSuk/T6\neMr9gW3M7FlJLwSQ9GrgPcCrgU2AX0ra0sxWFPA2Rqn0lYykCcDXgb0IH8ZBkl7V3VolMWDIzLar\nWoCJvkv4TOvNAOaY2ZbAVfF5lTSqswGnxc95u14PMBAiQsrWiJk9GR9OIvxR/hvwEeALZvZsLFML\nyG8DzjGzZ81sBLgbKOX/aqWDDOFN321mI/FD+jHhw+kFlR3ybWbXEv4D1tsfOCs+Pgt4e0crlaFJ\nnaHCn3MeayZujUhaTdI8YDFwtZndDmwJvFHS9ZKGJe0Qi28M3Fd3+H2EK5rCVf12aRPg3rrn9wE7\ndaku7TDC5edy4Ntm9p1uVyjBi8xscXy8GHhRNyvThiMlvR+YCxxTpVu8PJp9IefFrZV4q7OtpPWA\nKyQNxVNuYGY7S3otcB7w0manyFHlTFW/kunVBYh3NbPtgL2Bf5f0hm5XqB0WFn7uhc/+m8A0YFvg\nAeDU7lZn/JrdHr0WOLRua8XMlgK/AHYg/GG+IO6/CVghaQrwF2CzusM2jfsKV/UgM/aD2IzRl3iV\nZGYPxJ8PARdS0r1uwRZLejGApI2AJV2uTyYzW2IRcAa98Tm3NI7epSmS1o+P1wTeAtwKXAS8Oe7f\nEphkZg8DFwMHSpokaRqwBXBjGe+p6kFmLrCFpKmSJhFawy/ucp1akrSWpHXj47WBPYEF3a1VkouB\ng+Pjgwn/OSstBsOad9Abn3NL42j43Qj4VWyTuQG4xMyuAmYDL5W0ADgHeD+AmS0k3DotBC4DDreS\nUpeo6ilRJO3Nqi7sM83sCxmHdFX8q3BhfDoR+FHV6izpHOBNwBRC+8tngJ8R/tNtTjW7sMfW+QRg\niHCrZMCfgMPq2pV6jiSbn1h2Or2znkzlg4xzg0KSLUws+2p6J8hUvXfJuYHis7Cdc6Xqx7lLHmSc\nq5B+/EL243tyrmetnvqNXFZqNQrVlSCTNemx3VXbnauydhpoJ/ZhkOl471Kc9Ph7YA/CYLubgIPM\nbFFdGbvTNh113FdnLuWomeutfL6ljiioRv8o6DxjDRN6WLslpQlx7P/Uq4Ddx+x7NuE8KS0JGyaU\neSShTP37uowwqDrPeV5eUH2Oyvi9koOMJHty7ZSSsNbfvXeplZWTHgEk1SY9Lmp1kHODIPlKpod0\n4y316qRH50q3+hrdrkHxuhFkku7Pvjpz6crHOw2twU5DvfbpT+12BXKY1u0KtCnllqfThuOWk1/J\nFCJp0mN9+0tvmtrtCuTQbAWAqtqi2xVoYIjRbXGz2jvcg0whVk56BO4nTHo8qAv1cK56PMiMn5kt\nk3QEcAWrJj16o69zEL4RfaaSEyTDOJkTWpaxz2Rfhuqz92aWgUsSa5XlIwllvpVQpmqTiFO6wrdJ\nKHPXeCsSPZ5QJqXbvShZn8+MtrqwLXEFay3qnS7sqq8n49xgWSNxG6NZShRJp8R0KPMlXRCX5qwd\n05GUKB5knKuSnEvjmdlTwG5mti3h0nK3mBLlSmArM5sO3AkcB89JibIX8A1JpcQDDzLOVUne9Tdp\nmBLlETObU5dL6QbCWr7gKVGcG1ATErcGGqREGbsG1geAS+NjT4ni3EBq8o0cfjRsrTRKiWJmwwCS\nPgU8Y2ZntzpFjhpn8iDjXJU0+UYOTQlbzaw/Nz+FmS2VVEuJMizpEGAfRs9+9ZQozg2knG0yzVKi\nxGVVPgG8LTYO13QsJYpfyThXJfmn6G0EnBV7iFYDfmBmV0m6i9AQPEcSwG/N7HAzWyiplhJlGYOW\nEiVlMB5MzjzP9+zXmWUO0QEJNUpZVyRlXZqiyrjeMau9wXj/nHZWXdA7g/H8Ssa5KunDaQUeZJyr\nkj78RvbhW3Kuh/XhN7IP35JzPcxvl5xzperDb2QfviXnetjzul2B4nmQca5K/HbJOVeqPvxG9vBb\nyh6Md8hG52aWscOyxzPp2w8n1OeC7CITsxKBAcv+O+G1OrnyW4qUEWSXJZTxgYi9/I1spg/fknM9\nzG+XnHOl6sNvZB++Jed6WB9+I/vwLTnXw3otUWoCDzLOVUkffiN90SrnqiT/olWbSbpa0u2Sfifp\nqLh/R0k3SrpV0k2SXlt3TEdSovRh3HSuh+XvXXoW+LiZzZO0DnCzpDnAycCnzewKSXvH57uNSYmy\nCfBLSVvWZTYojAcZ56ok5zfSzB4EHoyPn5C0iBA8HgBqCd3WZ9U6vitTogAjkmopUa7PXfcmejjI\nJKxW9+D3Movo21dnlrFfTMkso31PzK7PsjnZZSo30G71hDLZKxD6QLtEBXwjJU0FtiMEjLuA6yR9\nidA8sksstjGjA0ppKVG8Tca5KhlH3iWAeKv0U+BoM3sCOBM4ysw2Bz4OzG7x6p4Sxbm+12QW9vDC\nsLUiaXXgfOCHZnZR3L2jme0RH/8UOCM+7lhKFA8yzlVJs7xL24StZtb5o3+vkIrgTGChmX257ld3\nS3qTmV0DvJmQDxtCSpSzJZ1GuE3ylCjODYT8vUu7Au8FbpN0a9z3SeDDwP9KWoPQMPZhgE6mRPEg\n41yV5O9duo7mbaw7NTnm88Dn871iOg8yzlVJH34j+/AtOdfDfKkH51ypfI3fKtkmu0jS2KLzMkto\n3y9mlrEPzcg+zxlZqXeLlDKILmXgX0qZxxLKpEipc4qqDWhsg1/JFEPSCOF/5nLgWTPbsRv1cK5y\nevjPfjPdeksGDJlZSiZ75waHB5lCZa/g7dyg6cMg0625S0aYWj5X0qFdqoNz1TPOuUtV1K24uauZ\nPSDphcAcSXeY2bWjiwzXPZ4aN+eqbiRuOfXhlUxX3pKZPRB/PiTpQsI6FmOCzFDH6+Xc+E1l9B/E\na9o7vA/X+O347ZKktSStGx+vDewJLOh0PZyrpJzLb1ZZN6r7IuDCMGmUicCPzOzKLtTDuerpsQCS\nQlkTLyWdAnyOMIPzcmA6YS3RH5RWKcmgUwPX1izoPNkrv/125RIfze2i9ye8Vsrgt5T35avVlW8W\nZpbUkyrJbEnaWbUhyefttpTbpT3N7DHgrYQWrZcBnyizUs4NKpuQtvWSlIuzWpm3Aj81s6XhSsM5\nV7TlfXi7lHIlc4mkO4DtgaskbQg8VW61nBtMyyembWM1y7tU9/tjJK2QNLluXzXyLpnZjNgus9TM\nlkn6OyGdgnOuYE+vMSmx5DNjdzTMu2RmiyRtBrwF+HOtcCfzLmVeyUh6N2ES4zJJnwZ+SEin4Jwr\n2PIJE5K2sczsQTObFx8/ASxi1ff0NOC/xhyyMu+SmY0AtbxLhUu5XfqMmT0m6fXA7oTFir9VRmWc\nG3TLmZC0tVKXd+kGSW8D7jOz28YU25iQa6mmtLxLKc1My+PPtwLfMbOfS/pcGZVxbtAtaxJAfjO8\njN8ML8s8vj7vErCCsJj4W+qLtDi8awuJ/0XS6YSKflHS8/CkcM6VYnmTr+ROQxPZaWjV81NnPf2c\nMmPzLknamjDHYX4c/Lopoa1mJyqWd+kAYC/gFDN7VNJGVGKcTMpgs+zI38lBa7vo55llrh/1797Y\nzsxNeLVfJpQpSspVdsrSQUUNDuzdFfayboWaaZR3ycwWEEbY18r8CdjezB6RVJ28S2b2d+B8SRtK\n2jzuvqOMyjg36PIGGZrkXTKzy+rKrLwdqlTeJUn7A6cSGoqWAC8htFxvVUaFnBtkT5PahT1aRt6l\nWpmXjnnekbxLKW0rJwK7AHea2TRCD9MNpdbKuQG1nIlJWy9JCTLPmtnDwGqSJpjZ1cAOJdfLuYFU\nRBd21aSExL/F9V+uBX4kaQnwRLnVcm4wVTWASLoZmA2cbWZ/a+fYlCuZtwNPAh8nLPVwN7Bfu5V0\nzmVbxoSkrQsOJPRC3STpx5L+X+zRypTSu1S7alkOfC93FZ1zmara3mJmdwGflHQ8YWDubGCFpNnA\nV1qlN2r6jiQ9QfMRgGZmzx9HnZ1zDVT1dglA0nTg34C9CYP+zgZeD/wK2LbZcU2DjJmtU3AdC5Yy\n0C5FUfnlUgaAZafE3ZnslLjzE9rdp3dsZUEIIxuydHJgW++mqX0mZxd22WKbzFLgDOBYM6sNOb5e\n0q6tjm11JbMjMMXMLh2zfx9gsZndPL5qO+fG6lJ7S4p3m9kfG/3CzN7R6sBWDb8nEUYDjrUQ+FJ6\n3ZxzqSo8TuZDktavPZG0gaQTUw5sFWTWjetMjBL3TWm3hs65bBUeJ7OPmT1aexK7sfdNObBVSFy/\nxe+KWuLfOVenwg2/q0l6npk9BSBpTUhrQGoVZK6S9N/A8bWJU5JWA2YRWpOdcwWrcJvMjwgxYTZh\nTZp/A76fcmCrIHMMoSX5D5LmxX3TgbnAh/LX1TnXzDMVzVNrZidJug3YgzC05bNmdkXKsa26sJ8A\nDpT0MsKMayOsVfGHAursnGugwrdLxGUjLsssOEbmtAIz+4OZXWxml3iAca5ceacVNEuJImmypDmS\n7pR05ZgeouSUKJLeGcs+JunxuKWkMq3oGOYkKQOuilohLUVKfYqp83Syew4fnnB8Zpkpy7MH/qWt\nVte7g9+qZhzd0w1TohDaTuaY2cmSjgVmADNypEQ5GXirmS1qt2K+Vq9zFZK3C7tJSpRNgP2Bs2Kx\nswgTnqH9lCgP5gkw0HrE7+RmvwNoNSHKOZdPEW0y9SlRgBeZ2eL4q8WsWvN3Y+D6usOyUqLMlXQu\ncBGrMsuZmV2QVZ9W12a3EBp7BWwO1NaQ2ICQiW5a1smdc+0Zb5CJt0rnA0eb2eP1qzGYmWXksW/1\nu/UI985j227yBxkzmwog6TvAhbU5TJL2BlrOVXDO5fN0ky7su4f/wh+GW2csqUuJ8gMzuyjuXizp\nxWb2YMw0UpvN2lZKFDM7JOkNNJDSJrNL/STJ2I31urwv6JxrrlkbzLShzdlj5i4rt7EapUSJLgYO\njo8PJtzu1PYfKGmSpGlkpESR9ApJV0m6PT7fJq4tkyklyNwv6XhJUyVNk/QpSkoC5dygG8fcpVpK\nlN0k3Rq3vYAvAm+RdCfw5vgcM1tIWHtkIWHsS1ZKlO8QslHW2mMWAAelvKeU/rKDgBOAC+Pz/0s9\nuXOuPXmnFWSkRNmjyTHtpERZy8xuqLXxxPadpLELKctv/hU4StLaMdGbc64kVV1+E3hI0strTyS9\nC3gg5cCU5G6vI8xhWhfYLC7Bd5iZHZ5x3GzCVPAlZrZ13DcZOJeQIG4EOKB++njxenGQWDF1nrL8\nZ5llTuBtmWVmdXSFPVfhaQVHAKcDr5R0P/An4F9TDkxpk/kyIRf2wwBmNh94U8Jx343H1ZtBGH24\nJXBVfO6ci6q6nkycXrQ7YS2pV5jZro3Wm2ok6drMzO4Zk/0gc4FdM7s2Dgqqtz+rAtRZwDAeaJxb\nKW+a2rJJOoFV4+asrm3ms1nHpgSZe2oLBUuaBBxFGLKcR7PRh845Kt0m83dWDdZbk5AWpdHyvM+R\n8o4+CnyFMOT4L8CVwL+3X8fREkYfOjdwqtomY2aj1vWWdAohFmRKCTJbmtm/jHmBXYFfJ9dwlWaj\nDxsYrns8NW7OVd1I3PKpapBpYG1az3VaKSXIfJ0w2SprX4ra6MOTGD36sIGhHKd3rtumMvoP4jVt\nHV3V5TclLah7uhqwIZDZHgOtZ2HvQpg+8EJJ/0Fo8IHQlZ3ZKyXpHEIj7xRJ9wKfIYw2PE/SB4ld\n2CmVdG5QVLhNZr+6x8sIudfGPRhvEiGgTIg/ax4D3pV1YjNrNiq44ejD9r2mmNOM49J2tJQEDimr\nY6QsEpViQWaJlDEwVzIrs8yeLSfv1sxMKJPyGaZ8Pp1MplHUv1dQ4dulsavgrTtmhnf7ubDN7Brg\nGknfNbM/j7uKzrlMVU1TS1j6ZeySL/cQepwMeGmzA1MG450xZl3QyZKSVil3zrUn7xq/HTCHsPzm\nC8zsBYTR/Fea2TQzaxpgIC3IvHBM5rhH8PEtzpWiwmlqcy/5klLb5ZJeUrtliqN4my027Jwbhwq3\nydwf14/5IaET6F9IXPIlJch8CrhW0v/F528EPpynls651iocZHIv+ZKy1MPlkrYHdiY08HzMzB7O\nWVHnXAt521sarXoQ9x8JHA4sB35hZsfG/ccBH4j7jzKzlqN3x7PkS9M2GUmvij+3J6wFej9h/YjN\nJRXVf+ycqzOONpnnrHogaTfCpORtzOyfgC/F/fU5l/YCvhHz3Dcl6XWSFgJ3xOfTJX0j5T21upL5\nD+BQ4FQar2K+W8oLOOfS5e3CbrLqwUeBL9QGzZnZQ3H/ypxLwIikWs6l62mutuTLz+K55ktKWfKl\n5TiZQ+PPoZQTdV7KRPCUgVIpYwNTBtHdklBmakKZxdlFCh4A1sqeZGeZtEXKLKNXpWSrLErnPp+i\nFdw9vQXwRkmfB54C/tPM5tJ+ziUg35Iv0HpawTtpkYclJamTc649zbqnlw7P47Hhee2ebiKwgZnt\nLOm1hIXDm41pyRq2nXvJl1a3S/vFF96Q0B/+q7h/N+A3JCR1cs61p1nv0jpD27PO0PYrn9836/sp\np7uP+D01s5skrZA0hTZzLkUfAb5KjiVfWt0uHQIQk3a/2sweiM83YlVuXedcgQruwr6IkAblGklb\nApPM7GFJFwNnSzqNEDSyci5NBL4ydsmXVCnjZDYDHqx7vpgwh8E5V7C8QaZu1YMX1K16MBuYHZdp\neAZ4P4ScS5JqOZeWkZFzycyWSXqJpDXM7Ol265YSZH4JXCHpbMJIv/cQ5jE45wrWLE1tlharHryv\nSfl2ci4B/BG4Ll4FPbnqNHZa1oEpQeZIQu7rN8Tn3zazC1uUd87lVLURv5J+YGbvI4y3+R/C2Lp1\n2jlHyohfk3QL8LiZzZG0lqR1zezxXLV2zjVVtSADbC9pY8KyDl9j1eJ1yVKSu32YMChvMvAyQkv0\nN4Hd230x51xrFVx+81uEHGkvBW4e87uW68jUqHWObZA0nzga0My2i/sW1M+PKFrIYnBiRqmiprun\nDNxKWdkiZRDd6gllOpn1MqU+KdbNLGE7HZ1ZRjekDNjr5EC7IlbYm4GZJf31l2Sb2l1JZ71PWySf\ntwiSvmVmH8lzbMo39Wkze7o20i92Z3kqE+dKUMHbJQDyBhhICzLXSPoUsJaktxBmdF6S9wWdc81V\nNciMR0qQORb4EGFl6sOAS4EzyqyUc4Pq6Wcqu8Zvbi2DTLw1+p2ZvRI4vTNVcm5wLV9W2ZQoubV8\nR3Gk3+/rl990zpVn+bLBvF2aDNwu6UZC0m0Iw2f2L69azg2mQQ0yx8ef9d1l3rvkXAmWPTtAQUbS\nmoTp3S8HbgNmp6aldM7ls2L5YLXJnEWYuXktsA9hPdDsEVWFyfqwi0ppmiJlZbxOpkYtKtYXdZ7s\nzzlloJ1tPCP7PPdnp9YtbtBjyr9p0uJw6QbsdulVtVG9ks4EbupMlZwbYE/135VMqxXKV4ZoMys4\nXDvnGlqWuI0habakxXHtmNq+UyQtkjRf0gWS1qv73XGS7pJ0h6Q9y3xLrYLMNpIer23A1nXPHyuz\nUs4NrJxBhgYpUQhLZG5lZtOBO4HjIF9KlPFotfxm/90cOld1Oe8ZGqVEMbP6xeVuAN4ZH+dJiZJb\n/90AOtfLyuu//QBwTnycKyVKXh5knKuS5cWfMk5wfsbMzm5RrLSxbx5knKuSZrdLtw7DvOG2Tyfp\nEMIQlPpF5vKkRMnNg4xzVfJUk/2vGgpbzfdmZZ5K0l7AJ4A3mVn9mdtKiTJemSvjdUNYGS+rXicl\nnCllUFZRHWUpr5US04saQNjJgWTZK+Olpei9O7PEFzkms8yMhNS68PyEMgn/N15/bOvfX6e2Vsbj\nF4nfx31Hn7cuJcoUwjKNJxB6kyaxajTpb83s8Fj+k4R2mmXA0WZ2RdoLt6+0KxlJs4F9gSV1g/pm\nEtamqSX+Ps7MLi+rDs71nPy9S41SosxuUb7dlCi5ldY3TuN+ewNOM7Pt4uYBxrl6+cfJVFZpVzKN\n+u2jji1+7FzP6cMpyGVeyTRzZBzmfKak9bvw+s5V1/LErYd0unfpm8Bn4+PPAacCH2xcdGbd46G4\nOVdxjw7D0uH8x/fYrVCKjgYZM1tSeyzpDFpmPZhZfoWcK9r6Q2GruTe7q3mUZl3YPayjQUbSRmb2\nQHz6DkIGBOdcjV/JpKvvt5d0L6HffkjStoRepj8RUqw452r6MMhUeDBe1oCqqqUrTalPUQP2UhT1\n+RSVordzn6HtcHxmGc1NGLB3fMZAO4ATL8sosE97g/FOTfw+HpM+yK/bfFqBc1XSh13YHmScq5Ie\n655O4UHGuSrx3iXnXKn6sOHXg4xzVeJtMs65UnmbjHOuVH14u9SNCZLOuWbGsdRDzKV0u6QFks6W\ntIakyZLmSLpT0pXdmJRc4SuZyRm/L21J0gaKGtiW8nEX9aesqFStKQPtUl6rcyv1ae6JmWVsh4SU\nuCemvK+C5WyTicuqHErI/Pq0pHOBA4GtgDlmdrKkY4EZcesYv5JxrkqeTtye6zFCiFpL0kRgLeB+\nYH9CXnviz7eXV/nGPMg4VyU5b5fM7BHC0in3EILLozG524vMrHY5upi0eSKFqvDtknMDqNnt0pJh\neGi46WGSXgZ8jLBi+1LgJ5LeW1/GzCzMC+wsDzLOVUmzLuwXDIWtZtFz1qnZAfiNmf0VQNIFwC7A\ng5JebGYPStoIWDL2wLL57ZJzVZK/d+kOYGdJa0oSsAewkLAw3MGxzMHARSXWviG/knGuSvKnRJkv\n6fvAXGAFcAtwOiEp1nmSPgiMAAcUUs82eJBxrkrGMa3AzE4GTh6z+xHCVU3XeJBxrkoad0/3tAoH\nmSIGwG2SUCZlUF/WwECAxxPKpAxISymT8lopqWMfyS6SlM61qJXxtkkoM5xQZuvMEpp7aWaZIyx7\nCeqvK+VzbkMfTiuocJBxbgD5LGznXKl8FrZzrlR+u+ScK5UHGedcqbxNxjlXKu/Cds6Vym+XnHOl\n6sPbpQqnqT09o1QnV8ZzvaWolLgJjpjZ+vdfT08nK8nYIPH7+DdPU+ucy8Nvl5xzpfIg45wrVR+2\nyfiiVc5VyThSogBImiDpVkmXxOddT4nSQ0Hm992uQJtGul2BHEa6XYE2jXS7AlV0NGFFvFoL8gxC\nSpQtgavocDoU8CBTopFuVyCHkW5XoE0j3a5ApUjaFNgHOAOo9Tx5ShTnXGH+B/gEYfnNGk+J4pyr\n16zl95q4NSbprcASM7tV0lCjMt1KiVLhwXjO9Ye2BuPxZOJZ1xp1XkmfB95HaBZ+HmFJwwuA1wJD\ndSlRrjazV7b1BsapkkHGuUEUgszSxNLrNQ1ekt4E/KeZ7SfpZOCvZnaSpBnA+mbW0cZfv11yrlIK\nmu6wqnfpi3Q5JYpfyThXEeFK5t7E0pv53CXnXB79N6/Ag4xzldJ/8wp8nExFSHq7pBWSXpFQ9mOS\nUtYzaHb8IZK+1uR3e0u6SdLtkm6R9KW4f6akY/K+pks1znkFFeRBpjoOAn4ef2Y5GlhrHK/VsCFO\n0j8BXwP+1cy2AnYA7mp1jCvas4lb7/AgUwGS1gF2Ao4A3lO3f4KkL0laIGm+pCMkHQlsDFwt6apY\n7om6Y94l6bvx8X6Sro9XJHMkbZhRlf8CTjSzOwHMbIWZfbtBfQ+VdKOkeZJ+WruqkvTuWNd5kq6J\n+7aSdEOctDdf0svH8VENgH8kbr3Dg0w1vA243MzuAR6S9Jq4/8PA5sB0M5sO/MjMvgbcTxhgtXss\nV3+VUf/4WjPb2cxeA5xLCCKwal7LWFsBNyfU93wz29HMtgUWAR+M+z8N7Bn37xf3HQZ8xcy2A7YH\n7ks4/wDrv9slb/ithoMI804AfhKf3wLsDnzTzFYAmNnf2jzvZpLOA14MTAL+WEx12VrSicB6wDrA\n5XH/r4Gz4mteEPf9FvhUnLx3gZndXVAd+lRv3Qql8CuZLpM0GdgNOFPSnwgT3N5dXyThNPVXL/UN\nwl8Dvmpm2xCuKLIai28ntMNkvc73gMPjeWfVzmtmHwWOBzYDbpY02czOIVzV/AO4VNJuCe9ngPXf\nlYwHme57F/B9M5tqZtPMbHNgRNIbgDnAYZImAEjaIB7zOGFuSs1iSa+UtBrwDlYFg+cTbq0ADkmo\nyynAJyVtEV9vNUmHxd+JVQFvHeBBSasD760dLOllZnajmZ0APARsKmkaMBJv834GbJ1QjwHmDb+u\neAcCF47Zd37cfwZwD3CbpHms6nk6Hbi81vBLWIjo54TblfvrzjMT+ImkuYQvfS34GA16i8xsAfAx\n4BxJC4EFwLQGx3wauAG4jtAmU9t/sqTbJC0Afm1mtxGGsS+QdCuhzef7CZ/JAOu/KxmfVuBcRYRp\nBecnln6nTytwzuXRW93TKTzIOFcpvdXeksKDjHOV0lvtLSm84de5SsnfuyRpL0l3SLpL0rGdqW82\nv5JxrlLyXcnEYQ5fB/YgJIq/SdLFZraowMrl4kHGuUrJ3SazI3C3mY0ASPoxYbqKBxnnXL3cbTKb\nMHpZvfu3GlFWAAAAgUlEQVQIk267zoOMc5WSuwu7sgPePMg4Vykz8x74F8KcsZrNqMiMdx/x61wf\nkDSRkMt5d8LUkhuBg7zh1zlXCDNbJukI4ApgAnBmFQIM+JWMc65kPhjPOVcqDzLOuVJ5kHHOlcqD\njHOuVB5knHOl8iDjnCuVBxnnXKk8yDjnSvX/AfwozmQng2eDAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10698e650>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I wrote the model as a class in order for it to be easily looped over during train/validation testing and optimizing. Unfortunately I didn't have enough time to finish this part of the analysis so I have ommitted that code.\n",
      "\n",
      "I also tried applying the \"burstiness\" correction when counting word frequencies during training.  I found that that gave a lower percent of accuracy so I have also omitted that.\n",
      "\n",
      "If I had enough time, I would have tried using different variations of the vocabulary.  For example I would have tried omitting words that are not in the English dictionary.  I also would have tried omitting stop words, since I predict that they don't add any value to the strenght of the model.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}