{
 "metadata": {
  "name": "",
  "signature": "sha256:3d3a344c3b32eceac69f0f3554d5d6744a43682b2a340922b2b5b63ab39a2a4d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#DCT Analysis\n",
      "\n",
      "Last week we dealt with the KDD 1998 dataset which concerend donations to a charity.  The data set has a lot of non numeric features which require complicated coding as you saw.  This week we use an anonymized purly numeric dataset so we can skip the complications of real data and move onto modeling.\n",
      "\n",
      "The data is sourced from http://mlcomp.org/datasets/1571 and concerns identifying the gender (an anonymized binary flag -1/1) of people based on 800 anonymized numeric features.  Accoridng the the MLComp website, error rates of ~10% were found using linear models.\n",
      "\n",
      "We have provided a tab delimited version of the test/train data set in the data directory for your use."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import the libraries \n",
      "%pylab inline\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the train and test data into two data frames (train_data and test_data) put the label column into (train_y/test_y) and the non labels into (train_x/test_x)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Summarizing the Data\n",
      "Use pandas to describe the train_x data frame.  Note that the range of each column varies by a significant amount.  Use the Z-Scaleing method to normalize the data and make it suitable to modeling.\n",
      "\n",
      "Also ZScale the test_x data frame using the mean/standard deviation computed from the train_x data frame.  Afterwards summarize the train_x and test_x post processing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Studying The Target\n",
      "\n",
      "Now that we have normalized the input matrix, we move on to looking at the target.  What values does the target take on and what is the distribution of these values.  Look at both the test/training data seperatly.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From this we see that both data sets are nearly 50/50 positive/negative and have two classes (0 and 1) which makes this a good binary classification problem."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Supervised Modeling\n",
      "\n",
      "We choose to use logistic regression on this data set since it is a simple binary classification problem.\n",
      "\n",
      "Use sklearn's logistic regression trainer to createa logistic regression model using the training data set.  Make a histogram of the predicted value for the positive/negative examples of the training set.  Does it look like the model is able to strongly seperate the positive/negative examples of the training set?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now list the features with the 10 largest positive and negative coefficients.  Since the feature are anonymized they don't have very much meaning.  But if we had additional knowledge about the data set we could use this to give reasons for our predictions.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Testing the model\n",
      "\n",
      "We now test the trained model on the training/test set and see the performance.  First make a histogram of predicted scores for the positive/negative examples of the test data.  \n",
      "\n",
      "Then compute the accuracy (percent correctly predicted) given that a prediction of >0.5 is considered positive and <= 0.5 is negative.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}