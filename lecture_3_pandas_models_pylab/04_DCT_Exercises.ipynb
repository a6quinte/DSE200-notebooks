{
 "metadata": {
  "name": "",
  "signature": "sha256:5943288d009f08dd79f8d13087ead4749394c3b0280833a1bbd2cf5ab6407b0c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#DCT Analysis\n",
      "\n",
      "Last week we dealt with the KDD 1998 dataset which concerend donations to a charity.  The data set has a lot of non numeric features which require complicated coding as you saw.  This week we use an anonymized purely numeric dataset so we can skip the complications of real data and move onto modeling.\n",
      "\n",
      "The data is sourced from http://mlcomp.org/datasets/1571 and concerns identifying the gender (an anonymized binary flag -1/1) of people based on 800 anonymized numeric features.  Accoridng the the MLComp website, error rates of ~10% were found using linear models.  We hope to do better using some simple feature selection and feature engineering.\n",
      "\n",
      "We have provided a tab delimited version of the test/train data set in the data directory for your use."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import the libraries \n",
      "%pylab inline\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load the train and test data into two data frames (`train_data` and `test_data`). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data = pd.read_csv(\"data/train\",sep=\"\\t\")\n",
      "test_data  = pd.read_csv(\"data/test\",sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Separate the `label` column from `train_data` into two new data frames called `train_x` and `train_y`. `train_y` is to contain only the column titled `label` in `train_data` while `train_x` should contain all of the rest. `train_x` should contains 800 columns, check that this is the case.\n",
      "\n",
      "In a similar way partition `test_data` into two new data frames called `test_x` and `test_y`\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Summarizing the Data\n",
      "Use pandas to describe the `train_x` data frame.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the range of each column varies by a significant amount.  Use the Z-Scaling method to normalize the data and make it suitable to modeling. More specifically, for each column in `train_x` compute the average $\\mu$ and the standard deviation $\\sigma$. Then transform each value in the column from the original value $X$ to the Z-value $Z$ using the formula:\n",
      "\n",
      "$$ Z=\\frac{X-\\mu}{\\sigma} $$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use the values of $\\mu$ and $\\sigma$ computed from `train_x` to scale the values in `test_x`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Afterwards summarize the train_x and test_x post processing.  Train_x should have exactly 0 mean and 1 standard deviation while test_x should be nearly there."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Studying The Target\n",
      "\n",
      "Now that we have normalized the input matrix, we move on to looking at the target.  Within the train_y data frame, what is the percentage of positive examples?  This is our prior probability and the accuracy we will attain if we always guess positive.  Also measure the prior for the test_y frame and comment if there are major differences between the testing/training data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Supervised Modeling\n",
      "\n",
      "We choose to use logistic regression on this data set since it is a simple binary classification problem.  In this section we aim to train a logistic regression model that accurately predicts the class of each record.  We'll train using the train_x/train_y data frames and evaluate on the test_x/test_y data frames.\n",
      "\n",
      "###Baseline Model\n",
      "\n",
      "Use sklearn's linear model package to train a logistic regression model using the whole train_x/train_y data frames.  Then evaluate this model using the test_x/test_y data frames by computing the accuracy (% of correct predictions).  Store this computed accuracy as acc_baseline."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.linear_model  \n",
      "#train model and evaluate performance here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Simpler model \n",
      "While your previous model has good performance, it uses 800 features.  The high feature count means the model is difficult to explain and may result in overfitting (since there are under 800 records).  We wish to build a model with 10 features which also has good accuracy.\n",
      "\n",
      "As a first step towards this, find the 20 features which have the largest absolute coefficients in your old model and build a logistic regression model which only uses these 20 features.  Then measure the accuracy of this new model and comment on the impact to performance caused by just using these 20 features.\n",
      "\n",
      "To do this you will have to make copies of the train_x/test_x data frames which only have the 20 highest coefficient features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ten_best = #Code to find best features goes here\n",
      "\n",
      "train_x_ten_best = train_x[ten_best]\n",
      "test_x_ten_best = test_x[ten_best]\n",
      "\n",
      "#Train model/evaluate performance here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Basic Feature Engineering\n",
      "On the last homework we discussed some text -> numeric feature engineering functions which are commonly used; however, feature engineering is a wide field which is often much simpler.  In particular when you already have all numeric features simple mathematical functions often add significant power to your features.  This helps account for non linear relationships between the features and the target.  \n",
      "\n",
      "Commonly used functions include:\n",
      "\n",
      "1. Log\n",
      "2. Square root\n",
      "3. Squareing\n",
      "4. Sign (1 if the number is positive, 0 otherwise)\n",
      "5. Absolute Value\n",
      "6. Binning\n",
      "\n",
      "Make for each feature (FEATURE) in train_x/test_x create 3 new features: the square of the feature (FEATURE_SQ), the absolute value of the feature (FEATURE_ABS), and the sign of the feature (FEAUTRE_SIGN).  Thus you should have 3200 features in your test_x/train_x data frames."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in train_x.columns:\n",
      "    train_x[col + \"_SQ\"]   = #Code goes here\n",
      "    train_x[col + \"_ABS\"]  = #Code goes here\n",
      "    train_x[col + \"_SIGN\"] = #Code goes here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###PCA Feature Engineering\n",
      "\n",
      "These simple techniques allow non linear relationships between the features and the target to be captured.  However, one issue is that these features are all univariate and thus our model is unable to capture relationships of multiple variables to the target.  A common technique is to use product/ratio feature (IE F_0*F_1 or F_0/F_1); however, this becomes intractable since this will produced $O(n^2)$ features for $n$ input features.  Domain expertise can give you ideas on which interactions are likely important, but cannot help you find new insights.  \n",
      "\n",
      "One idea is to use unsupervised learning techniques such as PCA to try and capture these interactions.  Find the top 10 prinipal components of train_x and then add the PCA coefficints for train_x/test_x as features PCA_0, PCA_1, ..., PCA_9.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Feature Selection\n",
      "\n",
      "Earlier, we built a model with the top 10 features from our whole model.  This is a possible way of doing [feature selection](http://en.wikipedia.org/wiki/Feature_selection), or choosing a subset of features to build our model with.  However, this is not the best way for a variety of reasons which you'll come to understand in future classes.  \n",
      "\n",
      "One better method of feature which is easy to understand is [forward selection](http://en.wikipedia.org/wiki/Stepwise_regression).  In this process you start with a model with no features and then search for the single best feature to add.  After you've found it you keep searching for the next feature to add until some stopping criteria is reached.  In this part we will guide you through the process of writing such an algorithm.\n",
      "\n",
      "As a first step, write code which will find the best 1 feature model.  In otherwords, for each feature train a model and evaluate its acuracy on the test data.  Store the best model, the feature used, and its accuracy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that you have figured out how to do a single iteration of forward selection (going from 0 -> 1 feature), use the below boiler plate code to complete the algorithm.\n",
      "\n",
      "Since we want to find the best model with 20 features, we loop through feature selection 20 times.  Add the following steps:\n",
      "\n",
      "1. Train models using the features in $f$ + 1 additional feature\n",
      "2. Find the additional feature that results in the highest accuracy\n",
      "3. Add the best addditional feature to $f$ and the accuracy of the best model to $acc$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "acc = []\n",
      "f   = []\n",
      "\n",
      "for i in range(20):\n",
      "    #TODO: search for the best feature to add to features to maximize performance\n",
      "    #TODO: add the best feature to features\n",
      "    #TODO: add the accuracy of the best model to acc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now plot the accuracy as a function of the number of features.  Also plot a horizontal line showing the accuracy of the baseline model and the original 20 high coefficient feature model.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Discussion of Results\n",
      "Now discuss the results.  In particular address the following issues:\n",
      "\n",
      "1. With the feature engineering and forward selection is accuracy better than baseline attainable?  If so how many features are required to beat the baseline?\n",
      "2. Based on the trajectory of the accuracy plot, do you think more features will significantly improve accuracy?\n",
      "3. Do some of the most important features from the baseline model still show up in our final forward selection model?  Are they transformed?\n",
      "4. Do all 3 sets of features (raw, transformed, pca) appear in the final model?  Which set seems to be the most important?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}