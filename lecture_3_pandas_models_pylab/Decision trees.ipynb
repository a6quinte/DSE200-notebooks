{
 "metadata": {
  "name": "",
  "signature": "sha256:ef5309bf1a1670503eb21998bb2e002243e0358416e71e31b0a34b6a3484e1cf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import the libraries \n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -lrt ../../DSE200/data/kddcup98/*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-rw-r--  1 yoavfreund  staff  117167952 Jul 22  1998 ../../DSE200/data/kddcup98/cup98LRN.txt\r\n",
        "-rw-rw-r--  1 yoavfreund  staff  117943347 Jul 22  1998 ../../DSE200/data/kddcup98/cup98VAL.txt\r\n",
        "-rw-r--r--  1 yoavfreund  staff       4134 Oct 29 18:43 ../../DSE200/data/kddcup98/readme\r\n",
        "-rw-r--r--  1 yoavfreund  staff      56987 Oct 29 18:43 ../../DSE200/data/kddcup98/cup98dic.txt\r\n",
        "-rw-r--r--  1 yoavfreund  staff      15907 Oct 29 18:43 ../../DSE200/data/kddcup98/cup98QUE.txt\r\n",
        "-rw-r--r--  1 yoavfreund  staff      62956 Oct 29 18:43 ../../DSE200/data/kddcup98/cup98DOC.txt\r\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lrn=pd.read_csv('../../DSE200/data/kddcup98/cup98LRN.txt',error_bad_lines=False)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Skipping line 579: expected 481 fields, saw 961\n",
        "Skipping line 1120: expected 481 fields, saw 961\n",
        "\n",
        "Skipping line 2250: expected 481 fields, saw 961\n",
        "Skipping line 3325: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 5556: expected 481 fields, saw 961\n",
        "Skipping line 5764: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 6611: expected 481 fields, saw 961\n",
        "Skipping line 7220: expected 481 fields, saw 961\n",
        "Skipping line 7877: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 9272: expected 481 fields, saw 961\n",
        "Skipping line 9787: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 11962: expected 481 fields, saw 961\n",
        "Skipping line 12195: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 12379: expected 481 fields, saw 961\n",
        "Skipping line 12560: expected 481 fields, saw 1441\n",
        "Skipping line 14103: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 17083: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 18634: expected 481 fields, saw 961\n",
        "Skipping line 18698: expected 481 fields, saw 961\n",
        "Skipping line 19161: expected 481 fields, saw 961\n",
        "Skipping line 19545: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 20999: expected 481 fields, saw 961\n",
        "Skipping line 21185: expected 481 fields, saw 961\n",
        "Skipping line 21244: expected 481 fields, saw 961\n",
        "Skipping line 22520: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 22822: expected 481 fields, saw 961\n",
        "Skipping line 23461: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 24739: expected 481 fields, saw 961\n",
        "Skipping line 26597: expected 481 fields, saw 961\n",
        "Skipping line 26773: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 26952: expected 481 fields, saw 961\n",
        "Skipping line 27982: expected 481 fields, saw 961\n",
        "Skipping line 28378: expected 481 fields, saw 961\n",
        "Skipping line 28739: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 29160: expected 481 fields, saw 961\n",
        "Skipping line 30032: expected 481 fields, saw 961\n",
        "Skipping line 30103: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 31148: expected 481 fields, saw 961\n",
        "Skipping line 31389: expected 481 fields, saw 961\n",
        "Skipping line 31469: expected 481 fields, saw 961\n",
        "Skipping line 31629: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 34193: expected 481 fields, saw 961\n",
        "Skipping line 34826: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 35622: expected 481 fields, saw 961\n",
        "Skipping line 35635: expected 481 fields, saw 961\n",
        "Skipping line 35743: expected 481 fields, saw 961\n",
        "Skipping line 36365: expected 481 fields, saw 961\n",
        "Skipping line 36944: expected 481 fields, saw 961\n",
        "Skipping line 37070: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 37276: expected 481 fields, saw 961\n",
        "Skipping line 37645: expected 481 fields, saw 961\n",
        "Skipping line 38511: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 40056: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 41962: expected 481 fields, saw 961\n",
        "Skipping line 42866: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 43642: expected 481 fields, saw 961\n",
        "Skipping line 44400: expected 481 fields, saw 961\n",
        "Skipping line 44974: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 47506: expected 481 fields, saw 961\n",
        "Skipping line 47527: expected 481 fields, saw 961\n",
        "Skipping line 48173: expected 481 fields, saw 961\n",
        "Skipping line 48287: expected 481 fields, saw 961\n",
        "Skipping line 48651: expected 481 fields, saw 961\n",
        "Skipping line 48697: expected 481 fields, saw 961\n",
        "Skipping line 48940: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 49779: expected 481 fields, saw 961\n",
        "Skipping line 50179: expected 481 fields, saw 961\n",
        "Skipping line 50256: expected 481 fields, saw 961\n",
        "Skipping line 50619: expected 481 fields, saw 961\n",
        "Skipping line 50850: expected 481 fields, saw 961\n",
        "Skipping line 51200: expected 481 fields, saw 961\n",
        "Skipping line 51350: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 51573: expected 481 fields, saw 961\n",
        "Skipping line 51800: expected 481 fields, saw 961\n",
        "Skipping line 52948: expected 481 fields, saw 961\n",
        "Skipping line 53324: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 54147: expected 481 fields, saw 961\n",
        "Skipping line 55062: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 56234: expected 481 fields, saw 961\n",
        "Skipping line 56721: expected 481 fields, saw 961\n",
        "Skipping line 56936: expected 481 fields, saw 961\n",
        "Skipping line 57401: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 58964: expected 481 fields, saw 961\n",
        "Skipping line 59616: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 60560: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 62125: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 64208: expected 481 fields, saw 961\n",
        "Skipping line 64270: expected 481 fields, saw 961\n",
        "Skipping line 64927: expected 481 fields, saw 961\n",
        "Skipping line 65168: expected 481 fields, saw 961\n",
        "Skipping line 65269: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 66463: expected 481 fields, saw 961\n",
        "Skipping line 66571: expected 481 fields, saw 961\n",
        "Skipping line 67119: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 68162: expected 481 fields, saw 961\n",
        "Skipping line 69283: expected 481 fields, saw 961\n",
        "Skipping line 69452: expected 481 fields, saw 961\n",
        "Skipping line 69847: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 70556: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 73471: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 75018: expected 481 fields, saw 961\n",
        "Skipping line 75345: expected 481 fields, saw 961\n",
        "Skipping line 75867: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 76091: expected 481 fields, saw 961\n",
        "Skipping line 76309: expected 481 fields, saw 961\n",
        "Skipping line 76581: expected 481 fields, saw 961\n",
        "Skipping line 76747: expected 481 fields, saw 961\n",
        "Skipping line 77975: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 78599: expected 481 fields, saw 961\n",
        "Skipping line 78762: expected 481 fields, saw 961\n",
        "Skipping line 78870: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 81079: expected 481 fields, saw 961\n",
        "Skipping line 81638: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 82408: expected 481 fields, saw 961\n",
        "Skipping line 83004: expected 481 fields, saw 961\n",
        "Skipping line 83358: expected 481 fields, saw 961\n",
        "Skipping line 83742: expected 481 fields, saw 961\n",
        "Skipping line 83821: expected 481 fields, saw 961\n",
        "Skipping line 83927: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 84504: expected 481 fields, saw 961\n",
        "Skipping line 84702: expected 481 fields, saw 961\n",
        "Skipping line 86033: expected 481 fields, saw 961\n",
        "Skipping line 86122: expected 481 fields, saw 961\n",
        "Skipping line 86185: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 88960: expected 481 fields, saw 961\n",
        "Skipping line 89866: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 90502: expected 481 fields, saw 961\n",
        "Skipping line 90867: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 92743: expected 481 fields, saw 961\n",
        "Skipping line 93496: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Skipping line 94475: expected 481 fields, saw 961\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "/anaconda/lib/python2.7/site-packages/pandas/io/parsers.py:1130: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  data = self._reader.read(nrows)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(lrn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(95149, 481)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are going to use the decision tree software written by [Avinash Kak]( https://engineering.purdue.edu/kak/distDT/DecisionTree-2.2.3.html#DecisionTree)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl https://engineering.purdue.edu/kak/distDT/DecisionTree-2.2.3.tar.gz?download > DecisionTree-2.2.3.tar.gz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100  148k  100  148k    0     0   165k      0 --:--:-- --:--:-- --:--:--  165k\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!tar xzvf DecisionTree-2.2.3.tar.gz"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "x DecisionTree-2.2.3/\r\n",
        "x DecisionTree-2.2.3/Makefile\r\n",
        "x DecisionTree-2.2.3/DecisionTree.py\r\n",
        "x DecisionTree-2.2.3/setup.py\r\n",
        "x DecisionTree-2.2.3/DecisionTree-2.2.3.html\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/Test.py\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/TestBestFeatureCalculation.py\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/testdata.dat\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/DecisionTree.py\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/TestProbabilityCalculation.py\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/TestDecisionTreeInduction.py\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/TestEntropyCalculation.py\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/TestDecisionTreeClassification.py\r\n",
        "x DecisionTree-2.2.3/TestDecisionTree/training.dat\r\n",
        "x DecisionTree-2.2.3/PKG-INFO\r\n",
        "x DecisionTree-2.2.3/README\r\n",
        "x DecisionTree-2.2.3/Examples/\r\n",
        "x DecisionTree-2.2.3/Examples/test4_no_class_labels.dat\r\n",
        "x DecisionTree-2.2.3/Examples/classify_test_data_in_a_file_numeric.py\r\n",
        "x DecisionTree-2.2.3/Examples/generate_training_data_numeric.py\r\n",
        "x DecisionTree-2.2.3/Examples/generate_training_data_symbolic.py\r\n",
        "x DecisionTree-2.2.3/Examples/training4.dat\r\n",
        "x DecisionTree-2.2.3/Examples/testdata.dat\r\n",
        "x DecisionTree-2.2.3/Examples/generate_test_data_symbolic.py\r\n",
        "x DecisionTree-2.2.3/Examples/DecisionTree.py\r\n",
        "x DecisionTree-2.2.3/Examples/README_for_dat_files\r\n",
        "x DecisionTree-2.2.3/Examples/construct_dt_and_classify_one_sample_case1.py\r\n",
        "x DecisionTree-2.2.3/Examples/construct_dt_and_classify_one_sample_case2.py\r\n",
        "x DecisionTree-2.2.3/Examples/testdata_classlabels.dat\r\n",
        "x DecisionTree-2.2.3/Examples/param_symbolic.txt\r\n",
        "x DecisionTree-2.2.3/Examples/construct_dt_and_classify_one_sample_case4.py\r\n",
        "x DecisionTree-2.2.3/Examples/test4.csv\r\n",
        "x DecisionTree-2.2.3/Examples/evaluate_training_data1.py\r\n",
        "x DecisionTree-2.2.3/Examples/construct_dt_and_classify_one_sample_case3.py\r\n",
        "x DecisionTree-2.2.3/Examples/param_numeric.txt\r\n",
        "x DecisionTree-2.2.3/Examples/training4.csv\r\n",
        "x DecisionTree-2.2.3/Examples/README\r\n",
        "x DecisionTree-2.2.3/Examples/README_for_CSV_files\r\n",
        "x DecisionTree-2.2.3/Examples/evaluate_training_data2.py\r\n",
        "x DecisionTree-2.2.3/Examples/classify_by_asking_questions.py\r\n",
        "x DecisionTree-2.2.3/Examples/stage3cancer.csv\r\n",
        "x DecisionTree-2.2.3/Examples/classify_test_data_in_a_file_symbolic.py\r\n",
        "x DecisionTree-2.2.3/Examples/param_numeric_extremely_overlapping_classes.txt\r\n",
        "x DecisionTree-2.2.3/Examples/training3.csv\r\n",
        "x DecisionTree-2.2.3/Examples/test4_no_class_labels.csv\r\n",
        "x DecisionTree-2.2.3/Examples/training.dat\r\n",
        "x DecisionTree-2.2.3/Examples/training2.csv\r\n",
        "x DecisionTree-2.2.3/Examples/test4.dat\r\n",
        "x DecisionTree-2.2.3/Examples/param_numeric_strongly_overlapping_classes.txt\r\n",
        "x DecisionTree-2.2.3/Examples/training.csv\r\n",
        "x DecisionTree-2.2.3/MANIFEST.in\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm DecisionTree-2.2.3.tar.gz\n",
      "%cd DecisionTree-2.2.3/Examples/\n",
      "!ls -l\n",
      "!cat README"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rm: DecisionTree-2.2.3.tar.gz: No such file or directory\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Errno 2] No such file or directory: 'DecisionTree-2.2.3/Examples/'\n",
        "/Users/yoavfreund/academic.papers/Courses/DSE200/DSE200-notebooks/lecture_2_github_io_numpy_pandas/DecisionTree-2.2.3/Examples\n",
        "total 744\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff  199642 Jun 12 19:39 \u001b[31mDecisionTree.py\u001b[m\u001b[m\r\n",
        "-rw-r--r--  1 yoavfreund  staff    8751 May  3 07:16 README\r\n",
        "-rw-r--r--  1 yoavfreund  staff     395 Jun 18  2013 README_for_CSV_files\r\n",
        "-rw-r--r--  1 yoavfreund  staff    1621 Aug 15  2013 README_for_dat_files\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff    1693 Aug 15  2013 \u001b[31mclassify_by_asking_questions.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff    9744 May  3 02:24 \u001b[31mclassify_test_data_in_a_file_numeric.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff    3598 May  3 02:23 \u001b[31mclassify_test_data_in_a_file_symbolic.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff    2338 May  3 01:52 \u001b[31mconstruct_dt_and_classify_one_sample_case1.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff    2745 Jun 12 18:29 \u001b[31mconstruct_dt_and_classify_one_sample_case2.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff    2514 Aug 14  2013 \u001b[31mconstruct_dt_and_classify_one_sample_case3.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff    2414 Aug 16  2013 \u001b[31mconstruct_dt_and_classify_one_sample_case4.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff    1448 Sep  2  2013 \u001b[31mevaluate_training_data1.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff    1696 Sep  4  2013 \u001b[31mevaluate_training_data2.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff     710 Jun 18  2013 \u001b[31mgenerate_test_data_symbolic.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff     777 Sep  1  2013 \u001b[31mgenerate_training_data_numeric.py\u001b[m\u001b[m\r\n",
        "-rwxr-xr-x  1 yoavfreund  staff     715 Jun 18  2013 \u001b[31mgenerate_training_data_symbolic.py\u001b[m\u001b[m\r\n",
        "-rw-r--r--  1 yoavfreund  staff     415 Jun  9  2013 param_numeric.txt\r\n",
        "-rw-r--r--  1 yoavfreund  staff     436 Sep  1  2013 param_numeric_extremely_overlapping_classes.txt\r\n",
        "-rw-r--r--  1 yoavfreund  staff     436 Sep  1  2013 param_numeric_strongly_overlapping_classes.txt\r\n",
        "-rw-r--r--  1 yoavfreund  staff     603 Jun 17  2013 param_symbolic.txt\r\n",
        "-rw-r--r--  1 yoavfreund  staff    5519 Jun 18  2013 stage3cancer.csv\r\n",
        "-rw-r--r--  1 yoavfreund  staff     612 May  2 11:39 test4.csv\r\n",
        "-rw-r--r--  1 yoavfreund  staff    1997 May  2 11:41 test4.dat\r\n",
        "-rw-r--r--  1 yoavfreund  staff     472 May  2 11:42 test4_no_class_labels.csv\r\n",
        "-rw-r--r--  1 yoavfreund  staff    1917 May  2 11:42 test4_no_class_labels.dat\r\n",
        "-rw-r--r--  1 yoavfreund  staff    2551 Jun 18  2013 testdata.dat\r\n",
        "-rw-r--r--  1 yoavfreund  staff     530 Jun 18  2013 testdata_classlabels.dat\r\n",
        "-rw-r--r--  1 yoavfreund  staff    2918 Jun 18  2013 training.csv\r\n",
        "-rw-r--r--  1 yoavfreund  staff   10145 Jun 18  2013 training.dat\r\n",
        "-rw-r--r--  1 yoavfreund  staff    2905 Sep  1  2013 training2.csv\r\n",
        "-rw-r--r--  1 yoavfreund  staff    2910 Sep  1  2013 training3.csv\r\n",
        "-rw-r--r--  1 yoavfreund  staff    5933 May  2 11:39 training4.csv\r\n",
        "-rw-r--r--  1 yoavfreund  staff   18561 May  2 11:41 training4.dat\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r\n",
        "          IN ORDER TO BECOME FAMILIAR WITH THE DecisionTree MODULE\r\n",
        "          ========================================================\r\n",
        "\r\n",
        "\r\n",
        "(1) First run the scripts\r\n",
        "\r\n",
        "        construct_dt_and_classify_one_sample_case1.py\r\n",
        "\r\n",
        "        construct_dt_and_classify_one_sample_case2.py\r\n",
        "\r\n",
        "        construct_dt_and_classify_one_sample_case3.py\r\n",
        "\r\n",
        "        construct_dt_and_classify_one_sample_case4.py\r\n",
        "\r\n",
        "    as they are.  The first script is for the purely symbolic case, the\r\n",
        "    second for a case that involves both numeric and symbolic features, the\r\n",
        "    third for the case of purely numeric features, and the last for the\r\n",
        "    case when the training data is synthetically generated by the script\r\n",
        "    generate_training_data_numeric.py\r\n",
        "\r\n",
        "    Next, try to modify the test sample in these scripts and see what\r\n",
        "    classification results you get for the new test samples.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "(2) The second and the third scripts listed above use the training file\r\n",
        "    `stage3cancer.csv'. The first script named above uses the training\r\n",
        "    file `training.dat'.  And the last script named above uses the training\r\n",
        "    data file `training.csv'.  These training files serve as examples for:\r\n",
        "\r\n",
        "       stage3cancer.csv:   Example of a CSV training data file with both \r\n",
        "                           symbolic and numeric features\r\n",
        "\r\n",
        "       training.csv    :   Example of a CSV training data file for the\r\n",
        "                           purely numeric case.  Contains two classes, each\r\n",
        "                           a Gaussian distribution in 2D.  The parameters of\r\n",
        "                           the two Gaussians are in the file: \r\n",
        "                           `param_numeric.txt'\r\n",
        "\r\n",
        "       training.dt     :   Example of a `.dat' file.\r\n",
        "\r\n",
        "    Note again that you can use a CSV file for the cases of purely symbolic\r\n",
        "    data, purely numeric data, or a mixture of the two. However, a `.dat' \r\n",
        "    file can only be used for symbolic data.\r\n",
        "\r\n",
        "    There are two additional training data files in the directory:\r\n",
        "\r\n",
        "          training2.csv\r\n",
        "\r\n",
        "          training3.csv\r\n",
        "\r\n",
        "    These are similar to the file `training.csv' in the sense that \r\n",
        "    they both contain two classes, each a 2D Gaussian distribution.\r\n",
        "    The first, `training2.csv' was generated by \r\n",
        "    `generate_training_data_numeric.py ' using the parameter file\r\n",
        "\r\n",
        "           param_numeric_strongly_overlapping_classes.txt\r\n",
        "\r\n",
        "    and the second, `training3.csv' was generated by the script using\r\n",
        "    the parameter file\r\n",
        "\r\n",
        "           param_numeric_extremely_overlapping_classes.txt\r\n",
        "\r\n",
        "    Study the training datafiles carefully.  Now create your own \r\n",
        "    datafiles that follow the formatting guidelines in these data files\r\n",
        "    and create scripts similar to those in Item (1) above for \r\n",
        "    working with your data.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "(3) So far we have talked about classifying one test data record at a time.\r\n",
        "    You can place multiple test data records in a disk file and classify\r\n",
        "    them all in one go.  To see how that can be done, execute the following\r\n",
        "    two command lines in the `examples' directory:\r\n",
        "\r\n",
        "     classify_test_data_in_a_file_numeric.py   training4.csv   test4.csv   out4.csv\r\n",
        "\r\n",
        "     classify_test_data_in_a_file_symbolic.py  training4.dat   test4.dat   out4.dat\r\n",
        "\r\n",
        "    Each of these two scripts constructs the decision tree from the data in\r\n",
        "    the first argument file and then uses it to classify the data in the\r\n",
        "    second argument file.  The computed class labels are deposited in the\r\n",
        "    third argument file.\r\n",
        "\r\n",
        "    In general, the test data files should look identical to the training\r\n",
        "    data files.  Of course, for real-world test data, you will not have the\r\n",
        "    class labels for the test samples.  You are still required to reserve a\r\n",
        "    column for the class label, which now must be just the empty string \"\"\r\n",
        "    for each data record.  For example, the test data supplied in the\r\n",
        "    following two calls through the files test4_no_class_labels.csv and\r\n",
        "    test4_no_class_labels.dat uses the empty string \"\" for the class\r\n",
        "    labels:\r\n",
        "\r\n",
        "        classify_test_data_in_a_file_numeric.py  training4.csv  test4_no_class_labels.csv out4.csv\r\n",
        "\r\n",
        "        classify_test_data_in_a_file_symbolic.py  training4.dat   test4_no_class_labels.dat   out4.dat\r\n",
        "\r\n",
        "    For bulk classification for the numeric case, the output file can also\r\n",
        "    be a `.txt' file.  In that case, you will see white-space separate\r\n",
        "    results in the output file.  When you mention a `.txt' file for the\r\n",
        "    output for the numeric case, you can control the extent of information\r\n",
        "    placed in the output file by setting the variable\r\n",
        "    $show_hard_classifications in the script.  If this variable is set, the\r\n",
        "    output will show only the most probable class for each test data\r\n",
        "    record.\r\n",
        "\r\n",
        ">   TO REMIND THE READER AGAIN, IF YOUR TRAINING DATA USES JUST NUMERIC\r\n",
        ">   FEATURES OR A MIXTURE OF NUMERIC AND SYMBOLIC FEATURES, YOU MUST USE\r\n",
        ">   CSV FILES FOR TRAINING AND TEST DATA.\r\n",
        "\r\n",
        "\r\n",
        "===========================================================================\r\n",
        "\r\n",
        "\r\n",
        "             FOR USING A DECISION TREE CLASSIFIER INTERACTIVELY\r\n",
        "\r\n",
        "\r\n",
        "    Starting with Version 1.6 of the module, you can use the DecisionTree\r\n",
        "    classifier in an interactive mode.  In this mode, after you have\r\n",
        "    constructed the decision tree, the user is prompted for answers to the\r\n",
        "    questions regarding the feature tests at the nodes of the tree.\r\n",
        "    Depending on the answer supplied by the user at a node, the classifier\r\n",
        "    takes a path corresponding to the answer to descend down the tree to\r\n",
        "    the next node, and so on.  To get a feel for using a decision tree in\r\n",
        "    this mode, examine the script\r\n",
        "\r\n",
        "        classify_by_asking_questions.py\r\n",
        "\r\n",
        "    Execute the script as it is and see what happens.\r\n",
        "\r\n",
        "\r\n",
        "===========================================================================\r\n",
        "\r\n",
        "\r\n",
        "     EVALUATING THE CLASS DISCRIMINATORY POWER OF YOUR TRAINING DATA\r\n",
        "\r\n",
        "\r\n",
        "Given a training data file that contains data records and the associated\r\n",
        "class labels, one often wants to know the quality of the data in the file.\r\n",
        "In other words, one wants to know if a training data file contains\r\n",
        "sufficient information to discriminate between the different classes\r\n",
        "mentioned in the file.\r\n",
        "\r\n",
        "Starting with Version 2.2 of the DecisionTree module, you can now run a\r\n",
        "10-fold cross-validation test on your training data to find out how much\r\n",
        "class-discriminatory information is contained in the data.  The following\r\n",
        "two scripts in the Examples directory:\r\n",
        "\r\n",
        "       evaluate_training_data1.py\r\n",
        "\r\n",
        "       evaluate_training_data2.py\r\n",
        "\r\n",
        "As these scripts show, the following class \r\n",
        "\r\n",
        "       EvalTrainingData\r\n",
        "\r\n",
        "defined in the main DecisionTree module file makes it straightforward to\r\n",
        "evaluate the class discriminatory power your data (as long as it resides in\r\n",
        "a `.csv' file.)  This new class is is a subclass of the DecisionTree class\r\n",
        "in the module file.\r\n",
        "\r\n",
        "Both the `evaluate' scripts mentioned above are identical in terms of the\r\n",
        "usage logic shown.  The first is specifically for the training data file\r\n",
        "`stage3cancer.csv' and second for the training data files `training.csv',\r\n",
        "`training2.csv', and `training3.csv'.  The latter three data files contain\r\n",
        "two Gaussian classes that are increasingly overlapping.  You can see for\r\n",
        "yourself the decreasing quality of the training data as you evaluate first\r\n",
        "the training file `training.csv', then the training file `training2.csv',\r\n",
        "and finally the training file `training3.csv'.\r\n",
        "\r\n",
        "\r\n",
        "===========================================================================\r\n",
        "\r\n",
        "\r\n",
        "              GENERATING SYNTHETIC TRAINING AND TEST DATA\r\n",
        "\r\n",
        "\r\n",
        "    Starting with Version 1.6, you can use the module itself to generate\r\n",
        "    synthetic training and test data.  See the script\r\n",
        "\r\n",
        "        generate_training_data_numeric.py\r\n",
        "\r\n",
        "        generate_training_data_symbolic.py\r\n",
        "\r\n",
        "    for how to generate training data for the decision-tree classifier for\r\n",
        "    the purely numeric case and for the purely symbolic case.  The data is\r\n",
        "    generated according to the information placed in a parameter file in\r\n",
        "    each case.  These files must follow certain rules regarding the\r\n",
        "    declaration of the classes, the features, the possible values for the\r\n",
        "    features, etc.  An example of such a parameter file for the numeric\r\n",
        "    case is:\r\n",
        "\r\n",
        "        param_numeric.txt\r\n",
        "\r\n",
        "    and for the symbolic case:\r\n",
        "\r\n",
        "        param_symbolic.txt\r\n",
        "\r\n",
        "    A test-data file looks very much like a training data file, except that\r\n",
        "    the former does not contain the class labels for the different data\r\n",
        "    records.  See the script\r\n",
        "\r\n",
        "        generate_test_data_symbolic.py\r\n",
        "\r\n",
        "    for an example of how you can generate test data for the purely\r\n",
        "    symbolic case.  Note that the class labels for the test data are placed\r\n",
        "    in a separate file whose name is supplied in the script named above.\r\n",
        "    By comparing the classification labels obtained for each of the data\r\n",
        "    records with their true labels you can assess the accuracy of the\r\n",
        "    decision-tree classifier.\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd .."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/yoavfreund/academic.papers/Courses/DSE200/DSE200-notebooks/lecture_2_github_io_numpy_pandas/DecisionTree-2.2.3\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd .."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}