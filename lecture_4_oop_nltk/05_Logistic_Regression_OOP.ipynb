{
 "metadata": {
  "name": "",
  "signature": "sha256:fa895082816f2989129e1c8e026be93524a5f75df24c67da674a44f1a54fcf0a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Import the libraries \n",
      "%pylab inline\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Object Oriented Programming for Analysis\n",
      "\n",
      "Last week we explored feature engineering and binary classification on the DCT data set.  This was all well and good but due to the ad hoc nature of this it may be hard to reuse this code for analysis of a similar dataset.  In this notebook we guide you thought the creation of a set of classes to encapselate this code for reuseability.\n",
      "\n",
      "**The goal of this is to mostly reuse your code from the DCT analysis notebook.  In the process it is also a good chance to refactor your code**\n",
      "\n",
      "##Model Object\n",
      "\n",
      "As a first step, we wish to encapselate the training of a logistic regression training and model which uses a subset of the features in a class.  Below we have written a template for the LR_Model class which trains a model in the constructor and then encapselates the prediction/accuracy measuring code within the class.  Fill in the 3 methods.\n",
      "\n",
      "If you need to add any additional methods for use within the class, Python style is to give them names starting with an underscore.  For example if we needed an internal method to compute the accuracy it would be called \\_accuracy(p,y)\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load data for testing purposes\n",
      "train_x = pd.read_csv(\"../lecture_3_pandas_models_pylab/data/train\", sep=\"\\t\")\n",
      "train_y = train_x[\"label\"]\n",
      "del train_x[\"label\"]\n",
      "test_x = pd.read_csv(\"../lecture_3_pandas_models_pylab/data/test\", sep=\"\\t\")\n",
      "test_y = test_x[\"label\"]\n",
      "del test_x[\"label\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LR_Model:\n",
      "    def __init__(self, train_x, train_y, fields = None):\n",
      "        \"\"\"\n",
      "            Trains a logistic regression model using sklearn\n",
      "            \n",
      "            :param train_x the pandas data frame containing the features for the training data\n",
      "            :param train_y the pandas data frame containing the lables for the training data\n",
      "            :param fields  the list of features from train_x that should be used for training.  \n",
      "                           if None then train on all features       \n",
      "        \"\"\"\n",
      "        raise(\"Todo\")\n",
      "        \n",
      "    def predict(self, x):\n",
      "        \"\"\" Scores x using the logistic regression model and returns the series of preditions \"\"\"\n",
      "        raise(\"Todo\")\n",
      "        \n",
      "    def evaluate(self, x,y):\n",
      "        \"\"\" Scores x using the logistic regression model and returns the accuracy of the scores vs y \"\"\"\n",
      "        raise(\"Todo\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After this code is complete the following tests should return true"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = LR_Model(train_x,train_y)\n",
      "print model.evaluate(test_x,test_y) > .90"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = LR_Model(train_x,train_y,test_x.columns.tolist()[0:10])\n",
      "print model.evaluate(test_x,test_y) > 0.55"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Feature Engineering Class\n",
      "\n",
      "We now provide you with a class FE_Technique which exports single method *transform* which takes a data frame and returns a new data frame containing the original frame plus the features created by the specific feature engineering technique.  **Do not modify this code.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FE_Technique:\n",
      "    def __init__(self, train_x):\n",
      "        \"\"\"\n",
      "            Constructs the FE_Technique using training data.  The constructor can do any prepetory work if the\n",
      "            technique is data specific.\n",
      "        \"\"\"\n",
      "        self.pass_through = True\n",
      "        None\n",
      "        \n",
      "    def _technique(self, data_frame):\n",
      "        \"\"\"\n",
      "            A private abstract method which takes the data frame and creates a new data frame \n",
      "            containin ONLY the features generated by the specific feature engineering technique.\n",
      "            This method is overridden in specific techniques.\n",
      "        \"\"\"\n",
      "        raise (\"This method is abstract\")\n",
      "        \n",
      "    def transform(self, data_frame):\n",
      "        \"\"\"\n",
      "            Applies the feature engineering technique and returns a new data frame contaning the\n",
      "            input features plus the new features.  This should not be overridden in subclasses\n",
      "        \"\"\"\n",
      "        added_features = self._technique(data_frame)\n",
      "        if self.pass_through:\n",
      "            return pd.concat([data_frame, added_features], axis=1, ignore_index = True)\n",
      "        else:\n",
      "            return added_features\n",
      "        \n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now impliment these 3 techniques as subclasses fo the FE_Technique class:\n",
      "\n",
      "1. FE_Basic_Math - impliments the absolute value, sign, and squareing transforms seen in last weeks homework\n",
      "2. FE_Whiten - impliments the Whitening Z Transform we've seen the past two homeworks.  This should set self.pass_through to false so that only the whitened features are output.  *Hint: in later parts we may see data with standard deviations of 0 for certain columns, account for this case*\n",
      "3. FE_PCA - add the top **20** PCA coeficient features to the data frame"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FE_Basic_Math(FE_Technique):\n",
      "    def _technique(self, data_frame):\n",
      "        \"\"\"Applies the sign, abs, and square transforms to all fields in data_frame\"\"\"\n",
      "        raise(\"Todo\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class FE_Whiten(FE_Technique):\n",
      "    def __init__(self,train_x):\n",
      "        #Call the super class constructor\n",
      "        FE_Technique.__init__(self, train_x)\n",
      "        raise(\"Todo\")\n",
      "    \n",
      "    def _technique(self, data_frame):\n",
      "        raise(\"Todo\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Write FE_PCA HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After this code is complete the following code should run and produce a reasonable data frame"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Example usage\n",
      "bm = FE_Basic_Math(train_x)\n",
      "\n",
      "train_x_bm = bm.transform(train_x)\n",
      "wht = FE_Whiten(train_x_bm)\n",
      "\n",
      "train_x_bm_pca = wht.transform(train_x_bm)\n",
      "pca = FE_PCA(train_x_bm_pca)\n",
      "\n",
      "x = pca.transform(wht.transform(bm.transform(test_x)))\n",
      "x.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Feature Selection \n",
      "\n",
      "Now develop the Model_Learner class, on construction it takes a paramter max_features and exports a method larn which uses the given training/testing data to perform forward selection in the same manner as your last assignment.\n",
      "\n",
      "Use the two private methods `_find_next_feature` and `_forward_selection` to hold most of the specific logic, learn simply return the `_forward_slection` method (as it is currenlty defined)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Model_Learner:\n",
      "    def __init__(self, max_features = 20 ):\n",
      "        self.max_features = max_features\n",
      "    \n",
      "    def learn(self, train_x, train_y, test_x, test_y):\n",
      "        \"\"\"\n",
      "            Runs forward selection until self.max_features features are added.  \n",
      "            \n",
      "            :returns a list of tuples [(model, feature added, accuracy)] containing the forward selection results\n",
      "        \"\"\"\n",
      "        return self._forward_selection(train_x, train_y, test_x, test_y)\n",
      "        \n",
      "    def _find_next_feature(self, features, train_x, train_y, test_x, test_y):\n",
      "        raise (\"Todo\")\n",
      "        \n",
      "    def _forward_selection(self, train_x, train_y, test_x, test_y):\n",
      "        raise (\"Todo\")\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Modeling\n",
      "\n",
      "Now use your class structure to complete the following modeling tasks\n",
      "\n",
      "###DCT Analysis\n",
      "Load the DCT train/test data used in last week's assignment, apply the FE_Basic_Math, FE_PCA, and FE_Whiten transformers and then use the model learner to use forward selection.  List the 20 features added (in order of addition) and plot the accuracy vs number of features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Cover Type Analaysis\n",
      "We have created a sample of 10,000 data points from the UCI cover type data set.  The goal of this part of the assignment is to do a similar analysis as the DCT using your new class structure.  The data set is in SVM Light format, a very common format for binary classification.  Since we don't want to bog you down on the loading of the data we load the data for you here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import load_svmlight_file\n",
      "def read_svm_light(file):\n",
      "    X, y = load_svmlight_file(file) \n",
      "    return pd.DataFrame(X.todense()), pd.DataFrame(y-1)\n",
      "X, y = read_svm_light(\"cov_data\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that we have only loaded a single data frame. We have not provided a test/train split for you, you will perform this step in a later step.\n",
      "\n",
      "Before doing this, first use describe to analyze the X and the y data frames to look for any descrepencies."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Does anything stand out to you about this data?  In particular does it need to be whitened and are the classes balanced?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Test Train Split\n",
      "\n",
      "Now that we have loaded the data we wish to split the data 2 ways.  We wish to randomly split this dataset so that 70% will be used for training and 30% will be used for testing (this is a pretty common splitting method).  Split your X/y data frames into train_x/test_x and train_y/test_y.  Ensure that the alignment of the x rows and y rows stays the same.  *Hint: when you subset a data frame it may have a index which has missing values, this may cause problems with your feature engineering code.  Use df.reset_index(drop=True) to make sure all data frames have a normal index.*\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before continueing, use describe to make sure the training/testing data frames all look similar to the summary of the whole dataset.  In particular ensure the label distributions are similar."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Modeling\n",
      "\n",
      "Now apply your feature engineering techniques and use forward selection to train models with up to 20 features.  Plot the accuracy vs feature count as you did before."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Discussion\n",
      "\n",
      "*Note: these discussion questions are mostly to get you thinking, it will be read but not graded*\n",
      "\n",
      "Discuss the following questions and any other results you found interesting.\n",
      "\n",
      "Does your model achieve reasonable performance over the prior?\n",
      "\n",
      "Does the order of feature engineering matter?\n",
      "\n",
      "Does it look like adding more features would improve your model results?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    }
   ],
   "metadata": {}
  }
 ]
}