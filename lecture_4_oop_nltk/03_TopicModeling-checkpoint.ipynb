{
 "metadata": {
  "name": "",
  "signature": "sha256:458c73f35a6b780c411705c5f3910667504fc3503dd2637a35e4f9775e4ed55e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## comparing word distributions for different scores in amazong reviews ##\n",
      "This notebook provides an initial exploration of the data provided by [J. McAuley and J. Leskovec](http://snap.stanford.edu/data/web-Amazon-links.html)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl \"http://snap.stanford.edu/data/amazon/Sports_&_Outdoors.txt.gz\" > \"SportsOutdoors.txt.gz\"\n",
      "!gunzip SportsOutdoors.txt.gz\n",
      "!head -10 SportsOutdoors.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "import traceback\n",
      "from string import split\n",
      "import re\n",
      "from time import time\n",
      "\n",
      "import nltk\n",
      "stopwords=nltk.corpus.stopwords.words('english')+['']\n",
      "','.join(stopwords)\n",
      "\n",
      "def count_tokens(string):\n",
      "    \"\"\"partition a string into words, no punctuation, lowercase, return as a Counter.\"\"\"\n",
      "    words=[]\n",
      "    for word in re.split(r'[ \\t\\n\\;\\\"\\'\\`\\,\\.]+',string):\n",
      "        word=word.lower()\n",
      "        if not word in stopwords:\n",
      "            words.append(word)\n",
      "    return Counter(words)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Filter():\n",
      "    \"\"\" An abstract class from which all specific filters are derived \"\"\"\n",
      "    def __init__(self):\n",
      "        self.counter=None\n",
      "        pass\n",
      "    def rule(self,data):\n",
      "        \"\"\" Return true/False on a single piece of data \"\"\"\n",
      "        return True\n",
      "    def accumIfRule(self,data):\n",
      "        \"\"\" accumulate statistics if rule passes \"\"\"\n",
      "        pass\n",
      "    def filter(self,dataStream):\n",
      "        \"\"\" Create a stream that is a subset of a given stream\n",
      "        not sure how to make this so that each\"\"\"\n",
      "        for item in dataStream():\n",
      "            if self.rule(item):\n",
      "                yield item\n",
      "                \n",
      "class scoreFilter(Filter):\n",
      "    def __init__(self,score):\n",
      "        self.score=score\n",
      "        self.counter=Counter()\n",
      "        self.doc_counter=0\n",
      "        self.token_counter=0\n",
      "    def rule(self,block):\n",
      "        inscore=int(float(block['review/score'][0]))\n",
      "        return inscore==self.score\n",
      "    def accumIfRule(self,block):\n",
      "        if self.rule(block):\n",
      "            self.doc_counter+=1\n",
      "            tokens=count_tokens(block['review/text'][0])\n",
      "            self.counter += tokens\n",
      "            self.token_counter+= sum(tokens.values())\n",
      "            #print \"accum\",self.score, self.token_counter\n",
      "            \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keys = ['review/profileName', 'product/price', 'review/time', 'product/productId', 'review/helpfulness', 'review/summary', 'review/userId', 'product/title', 'review/score', 'review/text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "global count_all\n",
      "count_all=0\n",
      "\n",
      "def getBlocks(infile,p=1):\n",
      "    global count_all\n",
      "    block={}\n",
      "    for line in infile.readlines():\n",
      "        try:\n",
      "            if line.strip():   #if line not empty\n",
      "                key,value=split(line,':',maxsplit=1)\n",
      "                block[key.strip()]=value.strip(),\n",
      "            else:\n",
      "                count_all+=1\n",
      "                if random.uniform()<p:\n",
      "                    yield block\n",
      "                block={}\n",
      "        except:\n",
      "            print \"ERROR:\",line\n",
      "            traceback.print_exc()\n",
      "            raise Exception()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################### this takes a long time (hours) to complete\n",
      "###################### so instead of running it, go to the next cell, where the collected counts are loaded from a pkl file.\n",
      "1=0 # an obvious error to prevent you from running this code unless you really want to\n",
      "\n",
      "infile=open('/Users/yoavfreund/DSE200/DSE200/data/amazonProductReviews/SportsOutdoors.txt','r')\n",
      "tokenized_keys=['review/summary','review/text','product/title']\n",
      "\n",
      "filters=[scoreFilter(i) for i in range(1,6)]\n",
      "\n",
      "i=1\n",
      "t=time()\n",
      "for block in getBlocks(infile):\n",
      "    for filter in filters:\n",
      "        filter.accumIfRule(block)\n",
      "\n",
      "    if (i % 500)==0:\n",
      "        print i, count_all,time()-t\n",
      "        t=time()\n",
      "    if i>3000:\n",
      "        break\n",
      "    \n",
      "    i+=1\n",
      "\n",
      "infile.close()\n",
      "#print counters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The command used to generate counters.pkl\n",
      "#pickle.dump(counters,open('counters.pkl','w'))\n",
      "\n",
      "import pickle\n",
      "!rm counters.pkl*\n",
      "!curl \"http://yoav.hadoop.s3.amazonaws.com/amazonProductReviews/counters.pkl.gz\" > counters.pkl.gz\n",
      "!gunzip counters.pkl.gz\n",
      "counters = pickle.load(open('counters.pkl','r'))\n",
      "print [\"%d:%d\"%(i,len(counters[i])) for i in range(len(counters))]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sumCounters(List):\n",
      "    \"\"\" get a list of counts as input and return the counter corresponding to the sum \"\"\"\n",
      "    Sum=Counter()\n",
      "    for C in List:\n",
      "        Sum=Sum+C\n",
      "    return Sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "total=Counter()\n",
      "sums=[0]*6\n",
      "for i in range(6):\n",
      "    total=total+counters[i]\n",
      "    sums[i]=sum(counters[i].values())\n",
      "    \n",
      "total_words=sum(sums)\n",
      "print 'total words=',total_words\n",
      "DF=pd.DataFrame(index=total.keys(),data={'total':total.values()})\n",
      "\n",
      "for i in range(1,6):\n",
      "    tmp=counters[i]\n",
      "    tmp2=pd.Series(index=tmp.keys(),data=tmp.values())\n",
      "    DF['total'+str(i)]=tmp2\n",
      "DF=DF.sort(columns='total')\n",
      "DF.tail(5)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "stopwords=nltk.corpus.stopwords.words('english')+['']\n",
      "','.join(stopwords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove stopwords and words appearing fewer than 10 times\n",
      "keep_list=[not(word in stopwords) for word in DF.index]\n",
      "DFR=DF.ix[keep_list,:]\n",
      "DFR=DFR[DFR['total']>10]\n",
      "shape(DFR),shape(DF)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DF=DFR.sort(columns='total')\n",
      "DF.tail(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DF=DF.sort(columns='total',ascending=False)\n",
      "semilogy(DF['total'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def KL_DF(DF,col1,col2):\n",
      "    \"\"\" Compute the KL divergence Dkl(col1,col2), where col1,col2 are the names of two columns in the dataframe df,\n",
      "    return the distance and the count for C1 \"\"\"\n",
      "    #C1=DF[col1].dropna()\n",
      "    #C2=DF[col2].dropna()\n",
      "    C1=DF[col1]\n",
      "    C2=DF[col2]\n",
      "    select=(C1>0)*(C2>0)\n",
      "    C1=C1[select]\n",
      "    C2=C2[select]\n",
      "    Z1=float(sum(C1))\n",
      "    Z2=float(sum(C2))\n",
      "    P1=C1/Z1\n",
      "    P2=C2/Z2\n",
      "    #print sum(P1),sum(P2)\n",
      "    #print len(P1),len(P2)\n",
      "    log_ratio=log(P1/P2)\n",
      "    log_like=P1*log_ratio\n",
      "    log_like.sort(ascending=False)\n",
      "    return log_like,sum(log_like),log_ratio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "KL_DF(DF,'total5','total')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def JS_DF(DF,col1,col2):\n",
      "    \"\"\" Compute the Jensen-Shannon distance between two columns \"\"\"\n",
      "    DF1=DF[[col1,col2]]\n",
      "    combined=col1+'+'+col2\n",
      "    DF1[combined]=DF1[col1]+DF1[col2]\n",
      "    Z1=float(sum(DF1[col1]))\n",
      "    Z2=float(sum(DF1[col2]))\n",
      "    Z3=Z1+Z2\n",
      "    KL1=KL_DF(DF1,col1,combined)\n",
      "    KL2=KL_DF(DF1,col2,combined)\n",
      "    #print KL1[1],KL2[1]\n",
      "    weighted_KL=(Z1/Z3)*KL1[1]+(Z2/Z3)*KL2[1]\n",
      "    return weighted_KL,KL1[0],KL2[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(5,0,-1):\n",
      "    d=KL_DF(DF,'total'+str(i),'total')\n",
      "    DF['log_ratio'+str(i)]=d[2]\n",
      "    DF['log_likelihood'+str(i)]=d[0]\n",
      "    print 'i=%1d, KL_divergence=%f'%(i,d[1])\n",
      "    print 'evidence for',i,': ',','.join(d[0].index[:40])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DF.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DF=DF.fillna(0)\n",
      "DF.sort(columns='log_ratio1',ascending=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1,6):\n",
      "    for j in range(i+1,6):\n",
      "        d=JS_DF(DF,'total'+str(i),'total'+str(j))\n",
      "        print 'i=%1d, j=%1d, js_divergence=%f'%(i,j,d[0])\n",
      "        print 'evidence for',i,','.join(d[1].index[:10])\n",
      "        print 'evidence for',j,','.join(d[2].index[:10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from time import time\n",
      "infile=open('/Users/yoavfreund/DSE200/DSE200/data/amazonProductReviews/SportsOutdoors.txt','r')\n",
      "tokenized_keys=['review/summary','review/text','product/title']\n",
      "\n",
      "scores={i:[] for i in range(1,6)}\n",
      "\n",
      "i=1\n",
      "t=time()\n",
      "for block in getBlocks(infile):\n",
      "    tokens=count_tokens(block['review/text'][0])\n",
      "    for k in tokens.keys():\n",
      "        count=tokens[k]\n",
      "        score=np.zeros([6])\n",
      "        if k in DF.index:\n",
      "            for j in range(1,6):\n",
      "                score[j]+=count*DF['log_ratio'+str(j)][k]\n",
      "    for j in range(1,6):\n",
      "        scores[j].append(score[j])\n",
      "    if (i % 2000)==0:\n",
      "        print i, count_all,time()-t\n",
      "        t=time()\n",
      "    #if i>10000:\n",
      "    #    break\n",
      "    \n",
      "    i+=1\n",
      "\n",
      "infile.close()\n",
      "#print counters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!rm scores.pkl*\n",
      "!curl \"http://yoav.hadoop.s3.amazonaws.com/amazonProductReviews/scores.pkl.gz\" > scores.pkl.gz\n",
      "!gunzip scores.pkl.gz\n",
      "scores=pickle.load(open('counters.pkl','r'))\n",
      "[len(s) for s in scores]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=1\n",
      "mn,st= mean(scores[i]),std(scores[i])\n",
      "print mn,st\n",
      "norm_scores=(scores[i]-mn)/st\n",
      "#hist(norm_scores[abs(norm_scores)>4],bins=50);\n",
      "norm_scores=sort(norm_scores)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'std=',std(DF['log_ratio1'])\n",
      "hist(DF['log_ratio1'],bins=100);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Len=len(norm_scores)\n",
      "P=arange(0,1,1.0/Len)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.stats import norm\n",
      "figure(num=None, figsize=(8, 6), dpi=300, facecolor='w', edgecolor='k')\n",
      "semilogy(norm_scores,P)\n",
      "semilogy(norm_scores,norm.cdf(norm_scores))\n",
      "xlim([-5,0])\n",
      "ylim([1e-7,1])\n",
      "grid()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure(num=None, figsize=(8, 6), dpi=300, facecolor='w', edgecolor='k')\n",
      "semilogy(norm_scores,1-P)\n",
      "semilogy(norm_scores,1-norm.cdf(norm_scores))\n",
      "xlim([0,5])\n",
      "ylim([1e-7,1])\n",
      "grid()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!gzip scores.pkl\n",
      "!ls -lrt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=4;j=5\n",
      "d=JS_DF(DF,'total'+str(i),'total'+str(j))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}