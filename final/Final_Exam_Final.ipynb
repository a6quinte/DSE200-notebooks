{
 "metadata": {
  "name": "",
  "signature": "sha256:4161dcbf3be60d7b979f7a3869cb99f28ceaf59372ff876cfde6fb64fa7f646f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#DSE 200 Final Exam\n",
      "There are **seven** problems listed below in approximatly increacing difficulty and length.\n",
      "Most problems involve just a couple lines of code denoted by comments within the code.\n",
      "If a problem seems to require a ton of code you are likely over thiking it and should try to find a simpler solution.\n",
      "\n",
      "Here are the topics of each problem:\n",
      "1. Exception Handling\n",
      "2. Unix Piping\n",
      "3. Directory Walking\n",
      "4. Linear Regression\n",
      "5. Object Oriented Model Selection\n",
      "6. Scaping\n",
      "7. Part of Speech Tagging\n",
      "\n",
      "This test is open internet; however, communication with your peers/others is strictly prohibited.  \n",
      "\n",
      "Good Luck!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Exception Handling\n",
      "\n",
      "Write a function to add two numbers, if either of the arguements is not an int or float, throw a new ArguementsMustBeNumbers exception."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ArguementsMustBeNumbers(Exception):\n",
      "    None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_two(x,y):\n",
      "    if False: #Check types of x and y\n",
      "        raise ArguementsMustBeNumbers()\n",
      "    return x+y\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After this code is correctly implmented, the following code should print True 4 times (no exceptions should be uncaught)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print add_two(1,1)==2\n",
      "try:\n",
      "    add_two(\"t\",1)\n",
      "    print False\n",
      "except ArguementsMustBeNumbers:\n",
      "    print True\n",
      "try:\n",
      "    add_two(2,\"f\")\n",
      "    print False\n",
      "except ArguementsMustBeNumbers:\n",
      "    print True\n",
      "try:\n",
      "    add_two(\"t\",\"f\")\n",
      "    print False\n",
      "except ArguementsMustBeNumbers:\n",
      "    print True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Unix Piping \n",
      "\n",
      "Below we generate a file called ps_out which contains a details about all processes on our machine.  In particular it is a csv file containing the PID, Username which owns the process, and the percent of the CPU time occupied by it.\n",
      "\n",
      "We'll ask you to process this file using unix tools."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify this section\n",
      "!ps -Ao \"pid,user,%cpu\" | sed \"s/^ *//\" | sed \"s/  */,/g\" > ps_out\n",
      "!head ps_out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First using **only unix tools** count the number of processes by each user is running"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat ps_out #TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now again using **only unix tools** find the pid which is using the largest cpu %.\n",
      "\n",
      "Your output should only be a single number (the process id consuming the largest cpu amount), i.e. `30048`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat ps_out #TODO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Directory Walking\n",
      "\n",
      "Below we have written a program which uses os.walk, unix tools, and python to find the 3 longest files by line count within each directory under the /etc/ directory.\n",
      "\n",
      "However, it is currently has several problems which you are tasked with fixing.\n",
      "\n",
      "Here are the current problems which must be fixed:\n",
      "\n",
      "1. the output is not sorted by line count\n",
      "2. the \"total\" line listing the total lines across the directory is not a file and should be removed\n",
      "3. more than three files are being printed\n",
      "4. directories that contain no files are being printed\n",
      "\n",
      "These issues should be resolved by using a combintation of python and or unix commands.  Please ensure the output format is not changed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from itertools import chain,groupby\n",
      "for d,ds,fs in os.walk(\"/etc\"):\n",
      "    #TODO: 1) Make output sorted by line count\n",
      "    #      2) Remove the Total line\n",
      "    #      3) Limit to 3 files per directory\n",
      "    #      4) Ignore directories containing no files\n",
      "    \n",
      "    lines = !wc -l $d/* 2> /dev/null | sed \"s/^ *//\"\n",
      "    \n",
      "    files = []\n",
      "    for line in lines:\n",
      "        try:\n",
      "            fields = line.split(\" \")\n",
      "            files.append((int(fields[0]),fields[1]))\n",
      "        except ValueError:\n",
      "            print \"Bad line: \" + line\n",
      "                        \n",
      "    print \"Longest files in \" + d + \":\"\n",
      "    for lc, f in files:\n",
      "        print \"\\t%s\\t%d\" %(f,lc)\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Linear Regression\n",
      "\n",
      "In the file linear.csv there is a set of 100 x,y pairs of numbers in csv format.\n",
      "\n",
      "About 10% of the lines have a missing y value.\n",
      "\n",
      "Your goal is to do the following:\n",
      "\n",
      "1. Preprocess the data to remove any points with a missing y value\n",
      "2. Fit a linear regression model using sklearn's LinearRegression package\n",
      "3. Plot a scatter plot of the populated x,y pairs as blue points and the best fit linear regression line in red"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.linear_model import LinearRegression\n",
      "%pylab inline\n",
      "import matplotlib.pyplot as plt\n",
      "data = pd.read_csv(\"./linear.csv\")\n",
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Preprocess the data to remove any points with a missing y value"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_data = #Todo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fit a linear regression model using sklearn's LinearRegression package"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdl = #Todo\n",
      "\n",
      "#Print formula so we can see the best fit line\n",
      "m = mdl.coef_[0]\n",
      "b = mdl.intercept_\n",
      "print \"formula: y = %f x + %f\" % (m,b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot a scatter plot of the populated x,y pairs as blue points and the best fit linear regression line in red"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Todo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Object Oriented Model Selection\n",
      "\n",
      "Throughout the quarter, several problems have involved choosing the best model from a set of candidate models to get the best accuracy.\n",
      "\n",
      "Besides using it for selecting model hyperparmeters (as in grid search) or features, you can also use it to select the modeling techniques.  \n",
      "\n",
      "This problem is in two steps:\n",
      "\n",
      "1. We define four models by inheriting from a base model class.\n",
      "2. We use train/test errors to choose the best model\n",
      "\n",
      "#### The base model\n",
      "We'll make each technique implement a common interface BaseModel given below. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do not modify this code\n",
      "class BaseModel:\n",
      "    def __init__(self, train_x, train_y):\n",
      "        \"\"\"Abstract constructor, subclasses should train a model of their type here and store\n",
      "           it in a way that predict can be used to compute predictions\"\"\"\n",
      "        raise Exception(\"This is an abstract class\")\n",
      "        \n",
      "    def predict(self, x):\n",
      "        \"\"\"Abstract method to compute a single prediction given a single example x\"\"\"\n",
      "        raise Exception(\"This is an abstract class\")\n",
      "        \n",
      "    def score(self, xs, ys):\n",
      "        \"\"\"Returns the accuracy of this model using xs as a list of inputs and ys as a list of correct values.\"\"\"\n",
      "        return sum([(self.model.predict(x)-y)**2 for x,y in zip(xs,ys)])/len(xs)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that you have implemented the BaseModel, implement a class for LinearModel, QuadraticModel, CubicModel, and QuarticModel. Use numpy's [polyfit](http://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html) function to find the coefficients ($a_i$) using the training data given as parameters `train_x, train_y` to the constructor.\n",
      "\n",
      "The input to each model is the variable $x$ and the output is the variable $y$.  $a_i$ refers to the coefficients found by polyfit.\n",
      "\n",
      "* **LinearModel** $y=a_1x+a_0$\n",
      "* **QuadraticModel** $y=a_2x^2+a_1x+a_0$\n",
      "* **CubicModel** $y=a_3x^3+a_2x^2+a_1x+a_0$\n",
      "* **QuarticModel** $y=a_4x^4+a_3x^3+a_2x^2+a_1x+a_0$\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import polyfit\n",
      "\n",
      "class LinearModel(BaseModel):\n",
      "    def __init__(self, train_x, train_y):\n",
      "        #calculate coefficients\n",
      "        \n",
      "    def predict(self, x):\n",
      "        y = #use coeficients/formula to compute solution\n",
      "        return y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class QuadraticModel(BaseModel):\n",
      "    def __init__(self, train_x, train_y):\n",
      "        #calculate coefficients\n",
      "        \n",
      "    def predict(self, x):\n",
      "        y = #use coeficients/formula to compute solution\n",
      "        return y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class CubicModel(BaseModel):\n",
      "    def __init__(self, train_x, train_y):\n",
      "        #calculate coefficients\n",
      "        \n",
      "    def predict(self, x):\n",
      "        y = #use coeficients/formula to compute solution\n",
      "        return y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class QuarticModel(BaseModel):\n",
      "    def __init__(self, train_x, train_y):\n",
      "        #calculate coefficients\n",
      "        \n",
      "    def predict(self, x):\n",
      "        y = #use coeficients/formula to compute solution\n",
      "        return y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we evaluate each of these techniques on our data.  Fill in the parts of the function marked \"TODO\" below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Load Data, do not modify\n",
      "train = pd.read_csv(\"train_data.csv\")\n",
      "valid = pd.read_csv(\"validation_data.csv\")\n",
      "train_x = train[\"x\"].tolist()\n",
      "train_y = train[\"y\"].tolist()\n",
      "valid_x = valid[\"x\"].tolist()\n",
      "valid_y = valid[\"y\"].tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "techniques = [LinearModel, QuadraticModel, CubicModel, QuarticModel]\n",
      "\n",
      "train_error = []\n",
      "valid_error = []\n",
      "for technique in techniques:\n",
      "    mdl = #Todo: Learn model using technique\n",
      "    train_error.append(mdl.score(train_x,train_y))\n",
      "    valid_error.append(mdl.score(valid_x,valid_y))\n",
      "    \n",
      "#Todo: Find technique with minimum validation error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally plot the training and validation error on the same plot.  Have a legend denoting which line is validation/training error."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Todo: Plot data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Scraping\n",
      "\n",
      "Started as a travel journal, Lonely Planet has gone on to become the world\u2019s most successful travel publisher, and they maintain an award winning website giving all the necessary details a traveller could ask for. \n",
      "In this question we will try to use their website lonelyplanet.com to find the top sightseeing places in San diego and how far they are from our current location\n",
      "\n",
      "In order to do this, we will scrape the website to find the top sightseeing places and develop a table containing the name of the place and its corresponding latitude, longitude values. We will then define a function to calculate distance between two points given their latitude and longitude.\n",
      "\n",
      "You can take your current location as UCSD Rady School of Management, with Latitude 32.88661 and longitude -117.24128"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<font color=\"red\">**NOTE:**</font>\n",
      "\n",
      "If the following cell gives an error about  `No Module Named bs4` please execute the following command in a *terminal* (sudo doesn't work right within iPython Notebook)\n",
      "\n",
      "`sudo pip install BeautifulSoup4`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify\n",
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "import urllib\n",
      "import pandas as pd\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we download the index of san diego sights for us to process."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify\n",
      "website = \"http://www.lonelyplanet.com\"\n",
      "country = \"usa\"\n",
      "city = \"san-diego\"\n",
      "scrape_topic = \"sights\"\n",
      "base_url = website+\"/\"+country+\"/\"+city+\"/\"+scrape_topic+\"/\"\n",
      "r  = requests.get(base_url)\n",
      "data = r.text\n",
      "soup = BeautifulSoup(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once you have retrieved the entire data from the website, the next step is to extract the URLs corresponding to specific sights.\n",
      "\n",
      "In order to do so, we need to define a regular expression for the links in which we are interested. \n",
      "\n",
      "Browsing the HTML of the site we find URLs of the following type\n",
      "\n",
      "    1. /usa/san-diego/sights/\n",
      "    2. /usa/san-diego/sights/nature-wildlife/san-diego-zoo\n",
      "    3. /usa/san-diego/sights/architecture/hotel-del-coronado\n",
      "    4. /usa/san-diego/sights/?page2=id\n",
      "    5. /usa/san-diego/sights/?page1=id+data=x \n",
      "\n",
      "URLs like 2,3 correspond to pages of sights that we are interested in. On the other hand, URLs like 1,4,5 correspond to other information which is not of interest.\n",
      " \n",
      "Write a regex pattern which parses all links starting with /usa/san-diego/sights/ followed by more characters. Make sure that the pattern does not allow links with question marks such as 4,5."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pattern = #TODO: Write regex to match desired URLS here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is the code to extract your the sights using your pattern.  Double check that the links look to match the pattern you expect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify\n",
      "url_list = []\n",
      "for link in soup.find_all('a',href=re.compile(pattern)):\n",
      "    url_list.append(link.get('href'))\n",
      "url_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we extract the information about each sight, we provide the `makeRecord` function that takes a beutiful soup object and returns a Dictionary containing the location name, latitude, and longitude."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify\n",
      "def makeRecord(soup):\n",
      "    record = {}\n",
      "    record[\"title\"] = soup.find('h1').get_text().strip()\n",
      "    for div in soup.find_all('div'):\n",
      "        if div.has_attr('data-latitude'):\n",
      "            record[\"latitude\"] =div['data-latitude'] \n",
      "        if div.has_attr('data-longitude'):\n",
      "            record[\"longitude\"] =div['data-longitude'] \n",
      "    return record\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now loop through the sights pages you found and make records for each.  Fill in the template with the requested actions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "website = \"http://www.lonelyplanet.com\"\n",
      "sights_list = []\n",
      "\n",
      "for url in url_list:\n",
      "    new_url = website+url\n",
      "    r    = #Use requests to get web page data\n",
      "    soup = #Make a beutiful soup object of pulled data\n",
      "    rec  = makeRecord(soup)\n",
      "    sights_list.append(rec)\n",
      "    \n",
      "sights_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have a table of sightseeiing places imediately around us along with their latitudes and longitudes, use the below function to find distance of each of the sightseeing place from your current location"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify\n",
      "import math\n",
      "def getDistanceFromLatLonInKm(lat1,lon1,lat2,lon2) :\n",
      "    R = 6371 # Radius of the earth in km\n",
      "    dLat = deg2rad(lat2-lat1) # deg2rad below\n",
      "    dLon = deg2rad(lon2-lon1) \n",
      "    a = math.sin(dLat/2)*math.sin(dLat/2)+math.cos(deg2rad(lat1))*math.cos(deg2rad(lat2))*math.sin(dLon/2)*math.sin(dLon/2)\n",
      "\n",
      "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
      "    d = R * c #Distance in km\n",
      "    return d\n",
      "\n",
      "\n",
      "def deg2rad(deg) :\n",
      "  return deg * (3.1416/180)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now add a field to each record in `sights_list` called `distance` which reports the distance from the Rady School to it.  Then print the sights from closest to furthest"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myLat = 32.88661\n",
      "myLng = -117.24128\n",
      "\n",
      "for i in range(len(sights_list)):\n",
      "    #Todo: add distance to record i in sights list\n",
      "    \n",
      "#Todo: sort sights_list\n",
      "\n",
      "for record in sights_list:\n",
      "    print record\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part of speech tagging\n",
      "In this problem you are asked to use part of speech tagging to explore the statistical structure of the language used in a book.\n",
      "\n",
      "Part of speech (POS) tags are labels that are associated with individual words and indicate their semantic function in the language. The default NLTK tokenizer is one of the simplest and least accurate tokenizing programs, but it will suffice for this excercise.\n",
      "\n",
      "Here is an example of the tokens associated with the words in a simple sentence\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not moidfy\n",
      "import nltk\n",
      "nltk.pos_tag(nltk.word_tokenize(\"I ate the apple\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Part of speech tags\n",
      "\n",
      "The `nltk.help` module contains documentation about each tag, including a definition and examples.\n",
      "You can query this documentation using either a complete tag or a regular expression. Note that the method prints the explanation, it returns `None`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify\n",
      "nltk.help.upenn_tagset('PRP')\n",
      "nltk.help.upenn_tagset('VBP')\n",
      "nltk.help.upenn_tagset('DT')\n",
      "nltk.help.upenn_tagset('NN*')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The corpus\n",
      "We will use the [brown corpus](http://en.wikipedia.org/wiki/Brown_Corpus) \n",
      "for this excercise. This corpus is one of the most popular datasets in computational studies of linguistics.\n",
      "\n",
      "First we load the brown corpus and view a few sentences."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify\n",
      "# Get the corpus as a sequence of sentences.\n",
      "sentences=nltk.corpus.brown.sents()\n",
      "\n",
      "# have a look at some sentences\n",
      "len(sentences)\n",
      "[' '.join(sentence) for sentence in sentences[1000:1010]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now create a histogram of the lenghts of all sentences."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Lengths= #Todo: Compute the number of words in each sentence\n",
      "\n",
      "hist(Lengths,bins=50);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see from the histogram, there are a large number of sentences in the Brown corpus.\n",
      "Lets make a subset called `shorts` containing only sentences with **exactly 9 words**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shorts=[]\n",
      "\n",
      "for sentence in sentences:\n",
      "    #Todo: add all 9 word sentences to shorts\n",
      "\n",
      "print len(sentences),len(shorts)\n",
      "print [' '.join(sentence) for sentence in shorts[:10]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Main part - count the words associated with each part of speech\n",
      "\n",
      "Next is the main part of this excercise in which we count, for each of the sentences in `Short`  the number of time each part of speech appears and the number of times each word is tagged with this part of speech. We then create a pretty summary of our findings."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# POS_counts is a dictionary of Counters. The keys to POS_counts are the POS acronyms.\n",
      "# The value is a counter that counts the number of time each word appears with the key POS.\n",
      "# This cell produces no output other than the values of the monitoring tracker `i`.\n",
      "\n",
      "from collections import Counter\n",
      "\n",
      "POS_counts={}\n",
      "\n",
      "i=0\n",
      "for sentence in shorts:\n",
      "    text = [word.lower() for word in sentence]\n",
      "    tagged_sent=nltk.pos_tag(text)\n",
      "\n",
      "    for (word,pos) in tagged_sent:\n",
      "        # Todo: Update POS_counts\n",
      "    \n",
      "    if i%100==0: print i,'\\r',   # the purpose of these two lines is to print a progress indicator\n",
      "    i+=1                         # in such a way that only one line of output is used.\n",
      "#This will take ~1-2 minutes to run"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute the total number of times each POS tag appeared"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "POS_total={}\n",
      "for t in POS_counts.keys():\n",
      "    POS_total[t] = #Todo: Sum of all of the counts for the POS tag t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we sort the entries of POS_counts in decreasing values of the counts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Do not modify\n",
      "import operator\n",
      "sorted_tags=sorted(POS_total.items(),key=operator.itemgetter(1),reverse=True)\n",
      "sorted_tags[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Print a Summary\n",
      "For each POS tag in decreasing number of occurances, print each of the following:\n",
      "1. The POS tag and its occurrence count\n",
      "2. The description of the tag, from nltk.help\n",
      "3. The top 10 most common words that appear with the tag\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for (tag,count) in sorted_tags:\n",
      "    #Todo: Print the POS tag and the number of times it occurs\n",
      "    \n",
      "    #Todo: Print nltk help on the given tag\n",
      "    \n",
      "    print 'Word Counts'\n",
      "    #Todo: Print the ten most common words tagged as tag\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}